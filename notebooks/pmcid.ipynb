{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of this notebook is to get full text articles from PMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.manifold import TSNE\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "import os, sys\n",
    "sys.path.append('../pubmed_rag')\n",
    "from utils import get_chunks\n",
    "from bioc import (\n",
    "    collapse_sections,\n",
    "    get_smaller_texts, \n",
    "    get_biocjson,\n",
    "    passages_to_df\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/test_pmid_list.csv', header=None)\n",
    "df.head()\n",
    "\n",
    "pmids = df[0].astype(str).to_list()\n",
    "#pmids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current status \n",
    "\n",
    "Getting full texts via biocjson from [Pubtator](https://www.ncbi.nlm.nih.gov/research/pubtator3/api) instead of [BioC API for PMC](https://www.ncbi.nlm.nih.gov/research/bionlp/APIs/BioC-PMC/)\n",
    "\n",
    "Why?? \n",
    "- I only have pmids currently, and Pubtator automatically links pmid to pmcid to return full text if it is available, otherwise returns abstract.\n",
    "- BioC API for PMC is not compatible with pmid id even though it says it does\n",
    "\n",
    "Bioc files\n",
    "- it looks like each 'passage' is a sentence\n",
    "- and the passages have annotations \n",
    "- additionally, relevant to us, the passage has metadata such as what section its from\n",
    "\n",
    "\n",
    "Steps\n",
    "- config\n",
    "    - provide list of pmids \n",
    "    - output path\n",
    "- retrieve biocjson (full text or abstract) and save to output path\n",
    "- for each json parse for text + section\n",
    "\n",
    "Vertex database of sentences or sections?\n",
    "Option 1:\n",
    "- embedd each sentence using [PubMedBERT now called BiomedBERT](https://huggingface.co/microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext)\n",
    "- keeping metadata\n",
    "\n",
    "Option 2:\n",
    "- collapse the sentences into one section \n",
    "- embed each section using same model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "sample = pmids[:15]\n",
    "max_tokens = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each pmid\n",
    "for pmid in sample:\n",
    "    \n",
    "    result = get_biocjson(pmid, 'biocjson')\n",
    "\n",
    "    if result is not None:\n",
    "        df_test = passages_to_df(result, 'biocjson')\n",
    "\n",
    "        # cleaning?\n",
    "        # lower case section names\n",
    "        df_test['section'] = df_test['section'].str.lower().str.strip()\n",
    "        # pmids to object\n",
    "        df_test['pmid'] = df_test['pmid'].astype(str)\n",
    "        df_test['date'] = pd.to_datetime(df_test['date'])\n",
    "        # also stripping sentences in case?\n",
    "        df_test['sentence'] = df_test['sentence'].str.strip()\n",
    "        punctuations = ('!',',','.','?',',','\"', \"'\")\n",
    "        # lol adding a . to the end for now? if no punc\n",
    "        df_test['sentence'] = np.where(\n",
    "            df_test['sentence'].str.endswith(punctuations), \n",
    "            df_test['sentence'], \n",
    "            df_test['sentence']+'.'\n",
    "        )\n",
    "        # which sections to keep? \n",
    "        keep_sections = ['title', 'abstract', 'intro', 'results', 'discuss', 'methods']\n",
    "        # filter \n",
    "        df_filtered = df_test[df_test['section'].isin(keep_sections)]\n",
    "\n",
    "        # grouping by section\n",
    "        collapsed = collapse_sections(df_filtered, 'biocjson')\n",
    "        # smaller texts within section\n",
    "        for i, section in enumerate(collapsed['text']):\n",
    "            smaller = get_smaller_texts(section, max_tokens)\n",
    "            collapsed.at[i, 'text'] = smaller\n",
    "        exploded = collapsed.explode('text')\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bkg-review-FcnO91kN-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
