{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of this notebook is to get full text articles from PMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "import requests\n",
    "\n",
    "# import nltk\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "#from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>doi</th>\n",
       "      <th>arxiv</th>\n",
       "      <th>pmid</th>\n",
       "      <th>publicationDate</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keywords</th>\n",
       "      <th>meshTerms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun2014</td>\n",
       "      <td>10.1039/C4IB00122B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25133803.0</td>\n",
       "      <td>2014-08-18</td>\n",
       "      <td>The integrated disease network</td>\n",
       "      <td>Kai Sun and Natalie Buchan and Chris Larminie ...</td>\n",
       "      <td>The growing body of transcriptomic, proteomic,...</td>\n",
       "      <td>\"phenotype, crohn's disease, heterogeneity, ge...</td>\n",
       "      <td>['Computational Biology / methods', 'Databases...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ernst2015</td>\n",
       "      <td>10.1186/s12859-015-0549-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25971816.0</td>\n",
       "      <td>2015-05-14</td>\n",
       "      <td>KnowLife: a versatile approach for constructin...</td>\n",
       "      <td>Patrick Ernst and Amy Siu and Gerhard Weikum</td>\n",
       "      <td>Background: Biomedical knowledge bases (KB's) ...</td>\n",
       "      <td>['Biomedical text mining','knowledge base','re...</td>\n",
       "      <td>['Biomedical Research', 'Humans', 'Information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Himmelstein2015</td>\n",
       "      <td>10.1371/journal.pcbi.1004259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26158728.0</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>Heterogeneous Network Edge Prediction: A Data ...</td>\n",
       "      <td>Daniel Himmelstein and Serio Baranzini</td>\n",
       "      <td>The first decade of Genome Wide Association St...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algorithms\\nAnimals\\nChromosome Mapping / meth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Himmelstein2017</td>\n",
       "      <td>10.7554/eLife.26726</td>\n",
       "      <td>10.1101/087619v3</td>\n",
       "      <td>28936969.0</td>\n",
       "      <td>2017-09-22</td>\n",
       "      <td>Systematic integration of biomedical knowledge...</td>\n",
       "      <td>Daniel Scott Himmelstein and Antoine Lizee and...</td>\n",
       "      <td>The ability to computationally predict whether...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Computational Biology / methods*\\nDrug Discove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Martinez2015</td>\n",
       "      <td>10.1016/j.artmed.2014.11.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25704113.0</td>\n",
       "      <td>2015-01-13</td>\n",
       "      <td>DrugNet: Network-based drug–disease prioritiza...</td>\n",
       "      <td>Víctor Martínez and Carmen Navarro and Carlos ...</td>\n",
       "      <td>Objective: Computational drug repositioning ca...</td>\n",
       "      <td>Data integration; Disease networks; Drug repos...</td>\n",
       "      <td>Area Under Curve\\nComputational Biology*\\nComp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name                            doi             arxiv  \\\n",
       "0          Sun2014             10.1039/C4IB00122B               NaN   \n",
       "1        Ernst2015      10.1186/s12859-015-0549-5               NaN   \n",
       "2  Himmelstein2015   10.1371/journal.pcbi.1004259               NaN   \n",
       "3  Himmelstein2017            10.7554/eLife.26726  10.1101/087619v3   \n",
       "4     Martinez2015  10.1016/j.artmed.2014.11.003                NaN   \n",
       "\n",
       "         pmid publicationDate  \\\n",
       "0  25133803.0      2014-08-18   \n",
       "1  25971816.0      2015-05-14   \n",
       "2  26158728.0      2015-07-09   \n",
       "3  28936969.0      2017-09-22   \n",
       "4  25704113.0      2015-01-13   \n",
       "\n",
       "                                               title  \\\n",
       "0                     The integrated disease network   \n",
       "1  KnowLife: a versatile approach for constructin...   \n",
       "2  Heterogeneous Network Edge Prediction: A Data ...   \n",
       "3  Systematic integration of biomedical knowledge...   \n",
       "4  DrugNet: Network-based drug–disease prioritiza...   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Kai Sun and Natalie Buchan and Chris Larminie ...   \n",
       "1       Patrick Ernst and Amy Siu and Gerhard Weikum   \n",
       "2             Daniel Himmelstein and Serio Baranzini   \n",
       "3  Daniel Scott Himmelstein and Antoine Lizee and...   \n",
       "4  Víctor Martínez and Carmen Navarro and Carlos ...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  The growing body of transcriptomic, proteomic,...   \n",
       "1  Background: Biomedical knowledge bases (KB's) ...   \n",
       "2  The first decade of Genome Wide Association St...   \n",
       "3  The ability to computationally predict whether...   \n",
       "4  Objective: Computational drug repositioning ca...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  \"phenotype, crohn's disease, heterogeneity, ge...   \n",
       "1  ['Biomedical text mining','knowledge base','re...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  Data integration; Disease networks; Drug repos...   \n",
       "\n",
       "                                           meshTerms  \n",
       "0  ['Computational Biology / methods', 'Databases...  \n",
       "1  ['Biomedical Research', 'Humans', 'Information...  \n",
       "2  Algorithms\\nAnimals\\nChromosome Mapping / meth...  \n",
       "3  Computational Biology / methods*\\nDrug Discove...  \n",
       "4  Area Under Curve\\nComputational Biology*\\nComp...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading in the publication list\n",
    "excel_file = 'data/bkg registry nelists.xlsx'\n",
    "pubs = pd.read_excel(excel_file, sheet_name='Publication')\n",
    "# check\n",
    "pubs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87 entries, 0 to 86\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   name             87 non-null     object        \n",
      " 1   doi              86 non-null     object        \n",
      " 2   arxiv            11 non-null     object        \n",
      " 3   pmid             76 non-null     float64       \n",
      " 4   publicationDate  87 non-null     datetime64[ns]\n",
      " 5   title            87 non-null     object        \n",
      " 6   authors          86 non-null     object        \n",
      " 7   abstract         87 non-null     object        \n",
      " 8   keywords         45 non-null     object        \n",
      " 9   meshTerms        65 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(8)\n",
      "memory usage: 6.9+ KB\n"
     ]
    }
   ],
   "source": [
    "pubs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmcid = \"25133803\" \n",
    "url = f'https://www.ncbi.nlm.nih.gov/research/bionlp/RESTful/pmcoa.cgi/BioC_xml/{pmcid}/unicode'\n",
    "\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PMC4448285.xml', \"wb\") as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def extract_full_text_from_bioc(xml_file):\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Initialize a list to store text passages\n",
    "    full_text = []\n",
    "\n",
    "    # Iterate through passages in the document\n",
    "    for document in root.findall(\".//document\"):\n",
    "        for passage in document.findall(\"passage\"):\n",
    "            # Extract the text content\n",
    "            text = passage.find(\"text\").text\n",
    "            if text:\n",
    "                full_text.append(text.strip())\n",
    "\n",
    "    # Join all passages into a single string with new lines\n",
    "    return \"\\n\\n\".join(full_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnowLife: a versatile approach for constructing a large knowledge graph for biomedical sciences\n",
      "\n",
      "Background\n",
      "\n",
      "Biomedical knowledge bases (KB's) have become important assets in life sciences. Prior work on KB construction has three major limitations. First, most biomedical KBs are manually built and curated, and cannot keep up with the rate at which new findings are published. Second, for automatic information extraction (IE), the text genre of choice has been scientific publications, neglecting sources like health portals and online communities. Third, most prior work on IE has focused on the molecular level or chemogenomics only, like protein-protein interactions or gene-drug relationships, or solely address highly specific topics such as drug effects.\n",
      "\n",
      "Results\n",
      "\n",
      "We address these three limitations by a versatile and scalable approach to automatic KB construction. Using a small number of seed facts for distant supervision of pattern-based extraction, we harvest a huge number of facts in an automated manner without requiring any explicit training.\n",
      "\n",
      "We extend previous techniques for pattern-based IE with confidence statistics, and we combine this recall-oriented stage with logical reasoning for consistency constraint checking to achieve high precision. To our knowledge, this is the first method that uses consistency checking for biomedical relations. Our approach can be easily extended to incorporate additional relations and constraints.\n",
      "\n",
      "We ran extensive experiments not only for scientific publications, but also for encyclopedic health portals and online communities, creating different KB's based on different configurations. We assess the size and quality of each KB, in terms of number of facts and precision. The best configured KB, KnowLife, contains more than 500,000 facts at a precision of 93% for 13 relations covering genes, organs, diseases, symptoms, treatments, as well as environmental and lifestyle risk factors.\n",
      "\n",
      "Conclusion\n",
      "\n",
      "KnowLife is a large knowledge base for health and life sciences, automatically constructed from different Web sources. As a unique feature, KnowLife is harvested from different text genres such as scientific publications, health portals, and online communities. Thus, it has the potential to serve as one-stop portal for a wide range of relations and use cases. To showcase the breadth and usefulness, we make the KnowLife KB accessible through the health portal (http://knowlife.mpi-inf.mpg.de).\n",
      "\n",
      "Electronic supplementary material\n",
      "\n",
      "The online version of this article (doi:10.1186/s12859-015-0549-5) contains supplementary material, which is available to authorized users.\n",
      "\n",
      "Introduction\n",
      "\n",
      "Large knowledge bases (KB's) about entities, their properties, and the relationships between entities, have become an important asset for semantic search, analytics, and smart recommendations over Web contents and other kinds of Big Data. Notable projects are DBpedia, Yago, and the Google Knowledge Graph with its public core Freebase (freebase.com).\n",
      "\n",
      "In the biomedical domain, KB's such as the Gene Ontology, the Disease Ontology, the National Drug File - Reference Terminology, and the Foundational Model of Anatomy are prominent examples of the rich knowledge that is digitally available. However, each of these KB's is highly specialized and covers only a relative narrow topic within the life sciences, and there is very little interlinkage between the KB's. Thus, in contrast to the general-domain KB's that power Web search and analytics, there is no way of obtaining an integrated view on all aspects of biomedical knowledge. The lack of a \"one-stop\" KB that spans biological, medical, and health knowledge, hinders the development of advanced search and analytic applications in this field.\n",
      "\n",
      "In order to build a comprehensive biomedical KB, the following three bottlenecks must be addressed.\n",
      "\n",
      "Beyond manual curation. Biomedical knowledge is advancing at rates far greater than any single human can absorb. Therefore, relying on manual curation of KB's is bound to be a bottleneck. To fully leverage all published knowledge, automated information extraction (IE) from input texts is mandatory.\n",
      "\n",
      "Beyond scientific literature. Besides scientific publications found in PubMed Medline and PubMed Central, there are substantial efforts on patient-oriented health portals such as Mayo Clinic, Medline Plus, UpToDate, Wikipedia's Health Portal, and there are also popular online discussion forums such as healthboards.com or patient.co.uk. All this constitutes a rich universe of information, but the information is spread across many sources, mostly in textual, unstructured and sometimes noisy form. Prior work on biomedical IE has focused on scientific literature only, and completely disregards the opportunities that lie in tapping into health portals and communities for automated IE.\n",
      "\n",
      "Beyond molecular entities. IE from biomedical texts has strongly focused on entities and relations at the molecular level; a typical IE task is to extract protein-protein interactions. There is very little work on comprehensive approaches that link diverse entity types, spanning genes, diseases, symptoms, anatomic parts, drugs, drug effects, etc. In particular, no prior work on KB construction has addressed the aspects of environmental and lifestyle risk factors in the development of diseases and the effects of drugs and therapies.\n",
      "\n",
      "Background\n",
      "\n",
      "The main body of IE research in biomedical informatics has focused on molecular entities and chemogenomics, like Protein-Protein Interactions (PPI) or gene-drug relations. These efforts have been driven by competitions such as BioNLP Shared Task (BioNLP-ST) and BioCreative. These shared tasks come with pre-annotated corpora as gold standard, such as the GENIA corpus, the multi-level event extraction (MLEE) corpus, and various BioCreative corpora. Efforts such as the Pharmacogenetics Research Network and Knowledge Base (PharmGKB), which curates and disseminates knowledge about the impact of human genetic variations on drug responses, or the Open PHACTS project, a pharmacological information platform for drug discovery, offer knowledge bases with annotated text corpora to facilitate approaches for these use cases.\n",
      "\n",
      "Most IE work in this line of research relies on supervised learning, like Support Vector Machines or Probabilistic Graphical Models. The 2012 i2b2 challenge aimed at extracting temporal relations from clinical narratives. Unsupervised approaches have been pursued by, to discover associations between genes and diseases based on the co-occurrence of entities as cues for relations. To further improve the quality of discovered associations, crowdsourcing has also been applied. Burger et al. uses Amazon Mechanical Turk to validate gene-mutation relations which are extracted from PubMed abstracts. Aroyo et al. describes a crowdsourcing approach to generate gold standard annotations for medical relations, taking into account the disagreement between crowd workers.\n",
      "\n",
      "Pattern-based approaches exploit text patterns that connect entities. Many of them manually define extraction patterns. Kolarik et al. uses Hearst patterns to identify terms that describe various properties of drugs. SemRep manually specifies extraction rules obtained from dependency parse trees. Outside the biomedical domain, sentic patterns leverage commonsense and syntactic dependencies to extract sentiments from movie reviews. However, while manually defined patterns yield high precision, they rely on expert guidance and do not scale to large and potentially noisy inputs and a broader scope of relations. Bootstrapping approaches such as use a limited number of seeds to learn extraction patterns; these techniques go back to. Our method follows this paradigm, but extends prior work with additional statistics to quantify the confidence of patterns and extracted facts.\n",
      "\n",
      "A small number of projects like Sofie/Prospera and NELL have combined pattern-based extraction with logical consistency rules that constrain the space of fact candidates. Nebot et al. harness the IE methods of for populating disease-centric relations. This approach uses logical consistency reasoning for high precision, but the small scale of this work leads to a very restricted KB. Movshovitz-Attias et al. used NELL to learn instances of biological classes, but did not extract binary relations and did not make use of constraints either. The other works on constrained extraction tackle non-biological relations only (e.g., birthplaces of people or headquarters of companies). Our method builds on Sofie/Prospera, but additionally develops customized constraints for the biomedical relations targeted here.\n",
      "\n",
      "Most prior work in biomedical Named Entity Recognition (NER) specializes in recognizing specific types of entities such as proteins and genes, chemicals, diseases, and organisms. MetaMap is the most notable tool capable of recognizing a wide range of entities. As for biomedical Named Entity Disambiguation (NED), there is relatively little prior work. MetaMap offers limited NED functionality, while others focus on disambiguating between genes or small sets of word senses.\n",
      "\n",
      "Most prior IE work processes only abstracts of Pubmed articles; few projects have considered full-length articles from Pubmed Central, let alone Web portals and online communities. Vydiswaran et al. addressed the issue of assessing the credibility of medical claims about diseases and their treatments in health portals. Mukherjee et al. tapped discussion forums to assess statements about side effects of drugs. White et al. demonstrated how to derive insight on drug effects from query logs of search engines. Building a comprehensive KB from such raw assets has been beyond the scope of these prior works.\n",
      "\n",
      "Contributions\n",
      "\n",
      "We present KnowLife, a large KB that captures a wide variety of biomedical knowledge, automatically extracted from different genres of input sources. KnowLife's novel approach to KB construction overcomes the following three limitations of prior work.\n",
      "\n",
      "Beyond manual curation. Using distant supervision in the form of seed facts from existing expert-level knowledge collections, the KnowLife processing pipeline is able to automatically learn textual patterns and harvest a large number of relational facts from such patterns. In contrast to prior work on IE for biomedical data which relies on extraction patterns only, our method achieves high precision by specifying and checking logical consistency constraints that fact candidates have to satisfy. These constraints are customized for the relations of interest in KnowLife, and include constraints that couple different relations. The consistency constraints are available as supplementary material (see Additional file 1). KnowLife is easily extensible, since new relations can be added with little manual effort and without requiring explicit training; only a small number of seed facts for each new relation is needed.\n",
      "\n",
      "Beyond scientific literature. KnowLife copes with input text at large scale - considering not only knowledge from scientific publications, but also tapping into previously neglected textual sources like Web portals on health issues and online communities with discussion boards. We present an extensive evaluation of 22,000 facts on how these different genres of input texts affect the resulting precision and recall of the KB. We also present an error analysis that provides further insight on the quality and contribution of different text genres.\n",
      "\n",
      "Beyond molecular entities. The entities and facts in KnowLife go way beyond the traditionally covered level of proteins and genes. Besides genetic factors of diseases, the KB also captures diseases, therapies, drugs, and risk factors like nutritional habits, life-style properties, and side effects of treatments.\n",
      "\n",
      "In summary, the novelty of KnowLife is its versatile, largely automated, and scalable approach for the comprehensive construction of a KB - covering a spectrum of different text genres as input and distilling a wide variety facts from different biomedical areas as output. Coupled with an entity recognition module that covers the entire range of biomedical entities, the resulting KB features a much wider spectrum of knowledge and use-cases than previously built, highly specialized KB's. In terms of methodology, our extraction pipeline builds on existing techniques but extends them, and is specifically customized to the life-science domain. Most notably, unlike prior work on biomedical IE, KnowLife employs logical reasoning for checking consistency constraints, tailored to the different relations that connect diseases, symptoms, drugs, genes, risk factors, etc. This constraint checking eliminates many false positives that are produced by methods that solely rely on pattern-based extraction.\n",
      "\n",
      "In its best configuration, the KnowLife KB contains a total of 542,689 facts for 13 different relations, with an average precision of 93% (i.e., validity of the acquired facts) as determined by extensive sampling with manual assessment. The precision for the different relations ranges from 71% (createsRisk: ecofactor x disease) to 97% (sideEffect:(symptom   disease) x drug). All facts in KnowLife carry provenance information, so that one can explore the evidence for a fact and filter by source. We developed a web portal that showcases use-cases from speed-reading to semantic search along with richly annotated literature, the details of which are described in the demo paper.\n",
      "\n",
      "Methods\n",
      "\n",
      "Overview of the KnowLife KB and processing pipeline.\n",
      "\n",
      "Our method for harvesting relational facts from text sources is designed as a pipeline of processing stages; Figure 1 gives a pictorial overview. A fact is a triple consisting of two entities e 1,e 2 and a relation R between them; we denote a fact by R(e 1,e 2). In the following, we describe the input data and each stage of the pipeline.\n",
      "\n",
      "Input sources\n",
      "\n",
      "Dictionary We use UMLS (Unified Medical Language System) as the dictionary of biomedical entities. UMLS is a metathesaurus, the largest collection of biomedical dictionaries containing 2.9 million entities and 11.4 million entity names and synonyms. Each entity has a semantic type assigned by experts. For instance, the entities IL4R and asthma are of semantic types Gene or Genome and Disease or Syndrome, respectively. The UMLS dictionary enables KnowLife to detect entities in text, going beyond genes and proteins and covering entities about anatomy, physiology, and therapy.\n",
      "\n",
      "KnowLife relations, their type signatures, and number of seeds\n",
      "\n",
      "Relation Domain Range Seed facts   Affects Disease Organ 23   Aggravates Ecofactor Disease 21   Alleviates Drug Disease 18   Causes Disease Disease 70   ComplicationOf Disease Disease 5   Contraindicates Drug Disease 26   CreatesRisk Ecofactor Disease 103   Diagnoses Device Disease 29   Interacts Drug Drug 9   IsSymptom Symptom or Disease Disease 69   ReducesRisk Drug or Behavior Disease 24   SideEffect Symptom or Disease Drug 12   Treats Drug Disease 58\n",
      "\n",
      "Relations KnowLife currently supports 13 binary relations between entities, each with a type signature constraining its domain and range (i.e., its left and right argument types). Table 1 shows that, for instance, the relation affects only holds between diseases and organs, but not between diseases and drugs. Each type signature consists of multiple fine-grained semantic types defined by UMLS; specifics for all relations are provided as supplementary material (see Additional file 2).\n",
      "\n",
      "Seed facts. A seed fact R(e 1,e 2) for relation R is a triple presumed to be true based on expert statements. We collected 467 seed facts (see Table 1) from the medical online portal uptodate.com, a highly regarded clinical resource written by physician authors. These seed facts are further cross-checked in other sources to assert their veracity. Example seed facts include i s S y m p t o m(C h e s t P a i n,M y o c a r d i a l I n f a r c t i o n) and c r e a t e s R i s k(O b e s i t y,D i a b e t e s).\n",
      "\n",
      "Overview of KnowLife's input corpus\n",
      "\n",
      "Genre Source Documents Sentences   Scientific Publications PubMed Medline 580,892 5,875,006    PubMed Central 12,532 2,765,580   Encyclopedic Articles Drugs.com 31,837 7,586,236    Mayo Clinic 2,166 570,325    Medline Plus 3,076 197,055    RxList 2,515 1,102,791    Wikipedia Health 20,893 787,148   Social Sources Healthboards.com 752,778 37,270,371    Patient.co.uk 44,610 1,081,420    Total 1,451,299 57,235,932\n",
      "\n",
      "Text Corpus. A key asset of this work is that we tap into different genres of text; Table 2 gives an overview. PubMed documents are scientific texts with specialized jargon; they have been the de-facto standard corpus for biomedical text mining. We took all PubMed documents published in 2011 that are indexed with disease-, drug-, and therapy-related MeSH (Medical Subject Heading) terms. We further prune out documents from inapplicable journals such as those not in the English language, or those about medical ethics. Web portals and encyclopedic articles are collaboratively or professionally edited, providing credible information in layman-oriented language. Examples include uptodate.com, mayoclinic.com, and the relevant parts of en.wikipedia.org. In contrast, discussion forums of online communities, where patients and physicians engage in discussions (often anonymously), have a colloquial language style, sometimes even slang. We tap into all three genres of text to demonstrate not only the applicability of our system, but also the amount of information buried in all of them. We use the Stanford CoreNLP software to preprocess all texts, such that they are tokenized, split into sentences, tagged with parts-of-speech, lemmatized, and parsed into syntactic dependency graphs.\n",
      "\n",
      "Entity recognition\n",
      "\n",
      "Anemia is a common symptom of sarcoidosis.\n",
      "\n",
      "Eventually, a heart attack leads to arrythmias.\n",
      "\n",
      "Ironically, a myocardial infarction can also lead to pericarditis.\n",
      "\n",
      "The first stage in the KnowLife pipeline identifies sentences that may express a relational fact. We apply entity recognition to every sentence: a sentence with one or more entities is relevant for further processing. To efficiently handle the large dictionary and process large input corpora, we employ our own method, using string-similarity matching against the names in the UMLS dictionary. This method is two orders of magnitude faster than MetaMap, the most popular biomedical entity recognition tool, while maintaining comparable accuracy. Specifically, we use locality sensitive hashing (LSH) with min-wise independent permutations (MinHash) to quickly find matching candidates. LSH probabilistically reduces the high-dimensional space of all character-level 3-grams, while MinHash quickly estimates the similarity between two sets of 3-grams. A successful match provides us also with the entity's semantic type. If multiple entities are matched to the same string in the input text, we currently do not apply explicit NED to determine the correct entity. Instead, using the semantic type hierarchy of UMLS, we select the most specifically typed entities. Later in the consistency reasoning stage, we leverage the type signatures to futher prune out mismatching entities. At the end of this processing stage, we have marked-up sentences such as\n",
      "\n",
      "where myocardial infarction and heart attack are synonyms representing the same canonical entity.\n",
      "\n",
      "Pattern gathering\n",
      "\n",
      "Pattern gathering in KnowLife.(a) Sentence-level pattern: Dependency graph of a sentence with recognized entities anemia and sarcoidosis. By computing the shortest path (bold lines) between the two entities, the word sequence symptom of is extracted. This sequence is extended by an adjectival modifier (amod) which results in the extracted pattern common symptom of. (b) Document-structure pattern: The entity Diclofenac is found within the document title and Belching within an <li> element. Take Diclofenac as the left-hand entity. By traversing the DOM tree downwards and coming across the heading Side Effects, we extract the heading's text as a pattern. Further traversal leads us to Belching, which yields the right-hand entity for the pattern.\n",
      "\n",
      "Our method extracts textual patterns that connect two recognized entities, either by the syntactic structure of a sentence or by a path in the DOM (Document Object Model) tree of a Web page. We extract two types of patterns: Sentence-level Patterns: For each pair of entities in a sentence, we extract a sequence of text tokens connecting the entities in the syntactic structure of the sentence. Specifically, this is the shortest path between the entities in the dependency graph obtained from parsing the sentence. However, this path does not necessarily contain the full information to deduce a relation; for instance, negations are not captured or essential adjectives are left out. Therefore, for every captured word the following grammatical dependencies are added: negation, adjectival modifiers, and adverbial modifiers. The resulting word sequence constitutes a sentence-level pattern. An example is shown in Figure 2(a). Document-structure Patterns: In Web portals like Mayo Clinic or Wikipedia, it is common that authors state medical facts by using specific document structures, like titles, sections, and listings. Such structures are encoded in the DOM tree of the underlying HTML markup. First, we detect if the document title, that is, the text within the <h1> tag in terms of HTML markup, is a single entity. Next, we detect if an entity appears in an HTML listing, that is, within an <li> tag. Starting from the <h1> tag, our method traverses the DOM tree downwards and determines all intermediate headings, i.e. <h2> to <h6> tags, until we reach the aforementioned <li> tag. The document title serves as left-hand entity, the intermediate headings as patterns, and the <li> text as right-hand entity. These are candidates for a relation or an entity argument in a relational fact. Figure 2(b) shows an example.\n",
      "\n",
      "Pattern analysis\n",
      "\n",
      "The goal of the pattern analysis is to identify the most useful seed patterns out of all the pattern candidates gathered thus far. A seed pattern should generalize the over-specific phrases encountered in the input texts, by containing only the crucial words that express a relation and masking out (by a wildcard or part-of-speech tag) inessential words. This way we arrive at high-confidence patterns.\n",
      "\n",
      "We harness the techniques developed in the Prospera tool. First, an itemset mining algorithm is applied to find frequent sub-sequences in the patterns. The sub-sequences are weighed by statistical analysis, in terms of confidence and support. We use the seed facts and their co-occurrences with certain patterns as a basis to compute confidence, such that the confidence for a pattern q in a set of sentences S is defined as\n",
      "\n",
      "where S X(R i) is the set of all entity tuples (e 1,e 2) appearing in any seed fact with relation R i and C X(R i) is the set of all entity tuples (e 1,e 2) appearing in any seed fact without relation R i. The rationale is that the more strongly a pattern correlates with the seed-fact entities of a particular relation, the more confident we are that the pattern expresses the relation. The patterns with confidence greater than a threshold (set to 0.3 in our experiments) are selected as seed patterns.\n",
      "\n",
      "Examples of seed facts and seed patterns as well as automatically acquired patterns and facts\n",
      "\n",
      "Seed facts Seed patterns Relations Confidences Patterns Harvested facts   causes(Tuberculosis,Pericarditis) progress createsRisk 0.5 which progresses to causes(Pericarditis,Tamponade)   createsRisk(Obesity,Diabetes)  causes 0.5 still progressing to createsRisk(Wart,Skincarcinoma)   createsRisk(Obesity,Asthma) risk factor createsRisk 1.0 children risk factors createsRisk(WoodDust,Asthma)   createsRisk(Malaria,Stillbirth)    have risk factors createsRisk(Golf,Tendinitis)       known risk factors createsRisk(GBvirusC,Hepatitis)   isSymptom(Pain,CrohnDisease) occur affects 0.67 occurs anywhere affects(Hashimoto's,ThyroidGland)   affects(Pericarditis,Heart)  isSymptom 0.33 occurs patients isSymptom(Anemia,Sarcoidosis)\n",
      "\n",
      "Each non-seed pattern p is then matched against the seed pattern set Q using Jaccard similarity to compute a weight w associating p with a relation.  The pattern occurrences together with their weights and relations serve as fact candidates. Table 3 shows sample seed patterns computed from seed facts. The table also gives examples for automatically acquired patterns and facts.\n",
      "\n",
      "Consistency reasoning\n",
      "\n",
      "The pattern analysis stage provides us with a large set of fact candidates and their supporting patterns. However, these contain many false positives. To prune these out and improve precision, the last stage of KnowLife applies logical consistency constraints to the fact candidates and accepts only a consistent subset of them.\n",
      "\n",
      "We leverage two kinds of manually defined semantic constraints: i) the type signatures of relations (see Table 1) for type checking of fact candidates, and ii) mutual exclusion constraints between certain pairs of relations. For example, if a drug has a certain symptom as a side effect, it cannot treat this symptom at the same time. These rules allow us to handle conflicting candidate facts. The reasoning uses probabilistic weights derived from the statistics of the candidate gathering phase.\n",
      "\n",
      "To reason with consistency constraints, we follow the framework of, by encoding all facts, patterns, and grounded (i.e., instantiated) constraints into weighted logical clauses. We extend this prior work by computing informative weights from the confidence statistics obtained in the pattern-based stage of our IE pipeline. We then use a weighted Max-Sat solver to reason on the hypotheses space of fact candidates, to compute a consistent subset of clauses with the largest total weight. Due to the NP-hardness of the weighted Max-Sat problem, we resort to an approximation algorithm that combines the dominating-unit-clause technique with Johnson's heuristic algorithm. Suchanek et al. has shown that this combination empirically gives very good approximation ratios. The complete set of consistency constraints is in the supplementary material (see Additional file 1).\n",
      "\n",
      "Results and discussion\n",
      "\n",
      "Evaluation of different text genres\n",
      "\n",
      "Relation Precision Harvested facts    Encyclopedic Scientific Encyclopedic + Encyclopedic + Encyclopedic Scientific Encyclopedic + Encyclopedic +    sources sources scientific scientific + sources sources scientific scientific +      sources social sources   sources social sources   Affects 0.855 +-0.047 0.762 +-0.049 0.825 +-0.047 0.767 +-0.048 1,278 450 2,388 5,053   Aggravates 0.810 +-0.041 0.459 +-0.044 0.829 +-0.049 0.785 +-0.049 130 371 432 708   Alleviates 0.953 +-0.039 0.735 +-0.048 0.786 +-0.046 0.736 +-0.048 903 4,433 4,530 6,790   Causes 0.904 +-0.039 0.674 +-0.049 0.801 +-0.049 0.792 +-0.049 28,119 19,203 47,463 62,407   Complication 0.917 +-0.039 0.397 +-0.049 0.897 +-0.041 0.869 +-0.046 1,011 1,475 1,524 1,566   Contraindicates 0.874 +-0.048 0.710 +-0.000 0.961 +-0.030 0.908 +-0.048 512 49 1,808 1,831   CreatesRisk 0.878 +-0.047 0.569 +-0.049 0.720 +-0.040 0.620 +-0.049 4,407 24,695 18,508 32,211   Diagnoses 0.964 +-0.035 0.839 +-0.049 0.860 +-0.048 0.840 +-0.047 813 5,920 4,832 9,743   Interacts 0.964 +-0.035 0.709 +-0.000 0.965 +-0.034 0.957 +-0.034 164,912 103 164,912 164,912   IsSymptom 0.891 +-0.042 0.482 +-0.050 0.858 +-0.048 0.694 +-0.048 4,878 2,320 6,395 11,017   ReducesRisk 0.797 +-0.045 0.637 +-0.046 0.762 +-0.048 0.751 +-0.049 1,712 4,684 4,489 5,865   SideEffect 0.956 +-0.038 0.826 +-0.000 0.964 +-0.035 0.971 +-0.026 270,600 139 270,709 271,416   Treats 0.850 +-0.048 0.581 +-0.045 0.898 +-0.041 0.566 +-0.048 11,915 9,318 14,699 35,803   Aggregated * 0.951 0.630 0.933 0.892 491,190 73,160 542,689 609,322\n",
      "\n",
      "*Precision values are averaged and numbers of harvested facts are summed.\n",
      "\n",
      "Evaluation of the impact of different components\n",
      "\n",
      "Relation Precision Harvested facts    Full pipeline Without Without Without Full pipeline Without Without Without    encyclopedic + document statistical consistency encyclopedic + document statistical consistency    scientific sources structure analysis reasoning scientific sources structure analysis reasoning   Affects 0.825 +-0.047 0.882 +-0.044 0.821 +-0.048 0.171 +-0.051 2,388 2,350 4,088 29,477   Aggravates 0.829 +-0.049 0.833 +-0.036 0.598 +-0.049 0.592 +-0.053 432 431 592 1,730   Alleviates 0.786 +-0.046 0.778 +-0.050 0.320 +-0.049 0.289 +-0.062 4,530 4,387 18,142 16,943   Causes 0.801 +-0.049 0.800 +-0.046 0.631 +-0.048 0.490 +-0.069 47,463 30,563 66,833 91,784   Complication 0.897 +-0.041 0.781 +-0.048 0.376 +-0.050 0.739 +-0.050 1,524 700 4,812 2,955   Contraindicates 0.961 +-0.030 0.914 +-0.043 0.122 +-0.049 0.630 +-0.059 1,808 365 26,298 15,279   CreatesRisk 0.720 +-0.040 0.750 +-0.044 0.386 +-0.047 0.406 +-0.067 18,508 17,282 77,158 48,159   Diagnoses 0.860 +-0.048 0.887 +-0.044 0.802 +-0.049 0.303 +-0.063 4,832 4,002 7,467 35,326   Interacts 0.965 +-0.034 0.858 +-0.046 0.953 +-0.047 0.941 +-0.049 164,912 392 200,935 187,201   IsSymptom 0.858 +-0.048 0.691 +-0.050 0.625 +-0.049 0.328 +-0.064 6,395 2,920 9,543 29,776   ReducesRisk 0.762 +-0.048 0.729 +-0.050 0.228 +-0.046 0.406 +-0.067 4,489 4,043 11,023 14,729   SideEffect 0.964 +-0.035 0.938 +-0.048 0.941 +-0.046 0.879 +-0.050 270,709 924 270,427 338,645   Treats 0.898 +-0.041 0.784 +-0.050 0.549 +-0.050 0.402 +-0.067 14,699 14,057 23,473 45,439   Aggregated * 0.933 0.784 0.777 0.707 542,689 82,416 720,791 857,443\n",
      "\n",
      "*Precision values are averaged and numbers of harvested facts are summed.\n",
      "\n",
      "We ran extensive experiments with the input corpora listed in Table 2, and created different KB's based on different configurations. We assess the size and quality of each KB, in terms of their numbers of facts and their precision evaluated by random sampling of facts. Tables 4 and 5 give the results, for different choices of input corpora and different configurations of the KnowLife pipeline, respectively. Recall is not evaluated, as there is no gold standard for fully comprehensive facts. To ensure that our findings are significant, for each relation, we computed the Wilson confidence interval at alpha = 5%, and kept evaluating facts until the interval width fell below 5%. An interval width of 0% means that all the facts were evaluated. Four different annotators evaluated the facts, judging them as true or false based on provenance information. As for inter-annotator agreement, 22,002 facts were evaluated; the value of Fleiss' Kappa was 0.505, which indicates a moderate agreement among all four annotators. The complete set of evaluated facts is in the supplementary material (see Additional file 3).\n",
      "\n",
      "Impact of different text genres\n",
      "\n",
      "We first discuss the results obtained from the different text genres: i) scientific (PubMed publications), ii) encyclopedic (Web portals like Mayo Clinic or Wikipedia), iii) social (discussion forums). Table 4 gives, column-wise, the number of facts and precision figures for four different combinations of genres.\n",
      "\n",
      "Generally, combining genres gave more facts at a lower precision, as texts of lower quality like social sources introduced noise. The combination that gave the best balance of precision and total yield was scientific with encyclopedic sources, with a micro-averaged precision of 0.933 for a total of 542,689 facts. We consider this the best of the KB's that KnowLife generated.\n",
      "\n",
      "The best overall precision was achieved when using encyclopedic texts only. This confirmed our hypothesis that a pattern-based approach works best when the language is simple and grammatically correct. Contrast this with scientific publications which often exhibit convoluted language, and online discussions with a notable fraction of grammatically incorrect language. In these cases, the quality of patterns degraded and precision dropped. Incorrect facts stemming from errors in the entity recognition step were especially rampant in online discussions, where colloquial language (for example, meds, or short for medicines) led to incorrect entities (acronym for Microcephaly, Epilepsy, and Diabetes Syndrome).\n",
      "\n",
      "The results vary highly across the 13 relations in our experiments. The number of facts depends on the extent to which the text sources express a relation, while precision reflects how decisively patterns point to that relation. Interacts and SideEffect are prime examples: the drugs.com portal lists many side effects and drug-drug interactions by the DOM structure, which boosted the extraction accuracy of KnowLife, leading to many facts at precisions of 95.6% and 96.4%, respectively. Facts for the relations Alleviates, CreatesRisk, and ReducesRisk, on the other hand, mostly came from scientific publications, which resulted in fewer facts and lower precision.\n",
      "\n",
      "A few relations, however, defied these general trends. Patterns of Contraindicates were too sparse and ambiguous within encyclopedic texts alone and also within scientific publications alone. However, when the two genres were combined, the good patterns reached a critical mass to break through the confidence threshold, giving rise to a sudden increase in harvested facts. For the CreatesRisk and ReducesRisk relations, combining encyclopedic and scientific sources increased the number of facts compared to using only encyclopedic texts, and increased the precision compared to using only scientific publications.\n",
      "\n",
      "As Table 4 shows, incorporating social sources brought a significant gain in the number of harvested facts, at a trade-off of lowered precision. As pointed out, there are facts that come only from social sources and, depending on the use case, it is still worthwhile to incorporate them; for example, to facilitate search and discovery applications where recall may be more important. Morever, the patterns extracted from encyclopedic and scientific sources could be reused to annotate text in social sources, so as to identify existing information.\n",
      "\n",
      "Number of fact occurrences in text sources\n",
      "\n",
      "Genre Source Fact occurrences   Scientific Publications PubMed Medline 39,266    PubMed Central 6,979   Encyclopedic Articles Drugs.com 461,130    Mayo Clinic 35,300    Medline Plus 6,559    RxList 5,818    Wikipedia Health 17,588\n",
      "\n",
      "Taking a closer look at the best experimental setting, we see that scientific and encyclopedic sources in KnowLife contribute to a different extent to the number of harvested facts. Table 6 shows the number of fact occurrences in our input sources. Recall that a fact can occur in multiple sentences in multiple text sources. Our experiments show that encyclopedic articles are more amenable for harvesting facts than scientific publications.\n",
      "\n",
      "Impact of different components\n",
      "\n",
      "In each setting, only one component was disabled, and the processing pipeline ran with all other components enabled. We used the KnowLife setting with scientific and encyclopedic sources, which, by and large, performed best, as the basis for investigating the impact of different components in the KnowLife pipeline. To this end, we disabled individual components: DOM tree patterns, statistical analysis of patterns, consistency reasoning - each disabled separately while retaining the others. This way we obtained insight into how strongly KnowLife depends on each component. Table 5 shows the results of this ablation study.\n",
      "\n",
      "No DOM tree patterns: When disregarding patterns on the document structure and solely focusing on textual patterns, KnowLife degrades in precision (from 93% to 78%) and sharply drops in the number of acquired facts (from ca. 540,000 to 80,000). The extent of these general effects varies across the different relations. Relations whose patterns are predominantly encoded in document structures - once again Interacts and SideEffect - exhibit the most drastic loss. On the other hand, relations like Affects, Aggravates, Alleviates, and Treats, are affected only to a minor extent, as their patterns are mostly found in free text.\n",
      "\n",
      "No statistical pattern analysis: Here we disabled the statistical analysis of pattern confidence and the frequent itemset mining for generalizing patterns. This way, without confidence values, KnowLife kept all patterns, including many noisy ones. Patterns that would be pruned in the full configuration led to poor seed patterns; for example, the single word causes was taken as a seed pattern for both relations SymptomOf and Contraindicates. Without frequent itemset mining, long and overly specific patterns also contributed to poor seed patterns. The combined effect greatly increased the number of false positives, thus dropping in precision (from 93% to 77%). In terms of acquired facts, not scrutinizing the patterns increased the yield (from ca. 540,000 to 720,000 facts).\n",
      "\n",
      "Relations mainly extracted from DOM tree patterns, such as Interacts and SideEffect, were not much affected. Also, relations like Affects and Diagnoses exhibited only small losses in precision; for these relations, the co-occurrence of two types of entities is often already sufficient to express a relation. The presence of consistency constraints on type signatures also helped to keep the output quality high.\n",
      "\n",
      "No consistency reasoning: In this setting, neither type signatures nor other consistency constraints were checked. Thus, conflicting facts could be accepted, leading to a large fraction of false positives. This effect was unequivocally witnessed by an increase in the number of facts (from ca. 540,000 to 850,000) accompanied by a sharp decrease in precision (from 93% to 70%).\n",
      "\n",
      "The relations Interacts and SideEffect were least affected by this degradation, as they are mostly expressed in the via document structure of encyclopedic texts where entity types are implicitly encoded in the DOM tree tags (see Figure 2). Here, consistency reasoning was not vital.\n",
      "\n",
      "Lessons learned: Overall, this ablation study clearly shows that all major components of the KnowLife pipeline are essential for high quality (precision) and high yield (number of facts) of the constructed KB. Each of the three configurations where one component is disabled suffered substantial if not dramatic losses in either precision or acquired facts, and sometimes both. We conclude that the full pipeline is a well-designed architecture whose strong performance cannot be easily achieved by a simpler approach.\n",
      "\n",
      "Error analysis\n",
      "\n",
      "Error analysis (number of facts in brackets)\n",
      "\n",
      "Percentage based on text genre   Percentage Cause of error Encyclopaedic Scientific Social     sources sources sources   8.16% (62) Preprocessing 38.71% (24) 3.23% (2) 58.06% (36)   27.24% (207) Entity Recognition 13.04% (27) 45.41% (94) 41.55% (86)   32.11% (244) Entity Disambiguation 12.30% (30) 26.23% (64) 61.48% (150)   1.97% (15) Coreferencing 13.33% (2) 13.33% (2) 73.33% (11)   13.68% (104) Nonexistent Relation 23.08% (24) 29.81% (31) 47.12% (49)   9.21% (70) Pattern Relation Duality 24.29% (17) 27.14% (19) 48.57% (34)   3.29% (25) Swapped left and right-hand entity 28.00% (7) 24.00% (6) 48.00% (12)   3.03% (23) Negation 17.39% (4) 21.74% (5) 60.87% (14)   1.32% (10) Factually Wrong 40.00% (4) 10.00% (1) 50.00% (5)\n",
      "\n",
      "Anemia is a common symptom of sarcoidosis.\n",
      "\n",
      "A common symptom of sarcoidosis is anemia.\n",
      "\n",
      "We analyzed the causes of error for all 760 facts annotated as incorrect from the experimental setting using the full information extraction pipeline and all three text genres. This setting allows us to compare the utility of the different components as well as the different genres. As seen in Table 7, we categorize the errors as follows: Preprocessing: At the start of the pipeline, incorrect sentence segmentation divided a text passage into incomplete sentences, or left multiple sentences undivided. This in turn lead to incorrect parsing of syntactic dependency graphs. In addition, there were incorrectly parsed DOM trees in Web portal documents. Not surprisingly, almost all preprocessing errors came from encyclopedic and social sources due to their DOM tree structure and poor language style, respectively. Entity Recognition: Certain entities were not correctly recognized. Complex entities are composed of multiple simple entities; examples include muscle protein breakdown recognized as muscle protein and breakdown, or arrest of cystic growth recognized as arrest and cystic growth. Paraphrasing and misspelling entities cause their textual expressions to deviate from dictionary entries. Idiomatic expressions were incorrectly picked up as entities. For instance, there is no actual physical activity in the English idiom in the long run. Entity Disambiguation: Selecting an incorrect entity out of multiple matching candidates caused this error, primarily due to two reasons. First, the type signatures of our relations were not sufficient to futher prune out mismatching entities during fact extraction. Second, colloquial terms not curated in the UMLS dictionary were incorrectly resolved. For example, meds for medicines was disambiguated as the entity Microcephaly, Epilepsy, and Diabetes Syndrome. Coreferencing: Due to the lack of coreference resolution, correct entities were obscured by phrases such as this protein or the tunnel structure. Nonexistent relation: Two entities might co-occur within the same sentence without sharing a relation. When a pattern occurrence between such entities was nevertheless extracted, it resulted in an unsubstantiated relation. Pattern Relation Duality: A pattern that can express two relations was harvested but assigned to an incorrect relation. For example, the pattern mimic was incorrectly assigned to the relation isSymptom. Swapped left and right-hand entity: The harvested fact was incorrect because the left- and right-hand entities were swapped. Consider the example fact i s S y m p t o m(A n e m i a,S a r c o i d o s i s), which can be expressed by either sentence:\n",
      "\n",
      "In both cases, the same pattern is a common symptom of is extracted. In sentence 2, however, an incorrect fact would be extracted since the order in which the entities occur is reversed. Negation: This error was caused by not detecting negation expressed in the text. The word expressing the negation may occur textually far away from the entities, as in It is disputed whether early antibiotic treatment prevents reactive arthritis, and thus escaped our pattern gathering method. In other cases, the negation phrase will require subtle semantic understanding to tease out, as in Except for osteoarthritis, I think my symptoms are all from heart disease. Factually Wrong: Although our methods successfully harvested a fact, the underlying text evidence made a wrong statement. Lessons learned: Overall, this error analysis confirms that scientific and encyclopedic sources contain well-written texts that are amenable to a text mining pipeline. Social sources, with their poorer quality of language style as well as information content, were the biggest contributor in almost all error categories. Errors in entity recognition and disambiguation accounted for close to 60% of all errors; overcoming them will require better methods that go beyond a dictionary, and incorporate deeper linguistic and semantic understanding.\n",
      "\n",
      "Coverage\n",
      "\n",
      "Top-20 pairs of inter-connected biomedical areas within KnowLife\n",
      "\n",
      "Biomedical areas  Connections   Disorders Chemicals 310482   Chemicals Chemicals 190160   Disorders Disorders 36677   Disorders Procedures 14169   Chemicals Physiology 5397   Disorders Genes 3831   Disorders Living Beings 2539   Chemicals Drugs 2455   Disorders Anatomy 2895   Disorders Devices 792   Disorders Activities 592   Disorders Drugs 511   Disorders Objects 505   Chemicals Procedures 544   Disorders Physiology 370   Procedures Physiology 123   Procedures Living Beings 99   Disorders Geographical Areas 82   Genes Physiology 51   Disorders Phenomena 50\n",
      "\n",
      "The overriding goal of KnowLife has been to create a versatile KB that spans many areas within the life sciences. To illustrate which areas are covered by KnowLife, we refer to the semantic groups defined by. Table 8 shows the number of acquired facts for pairs of the thirteen different areas inter-connected in our KB. This can be seen as an indicator that we achieved our goal at least to some extent.\n",
      "\n",
      "The predominant number of facts involves entities of the semantic group Disorders, for two reasons. First, with our choice of relations, disorders appear in almost all type signatures. Second, entities of type clinical finding are covered by the group Disorders, and these are frequent in all text genres. However, this type also includes diverse, non-disorder entities such as pregnancy, which is clearly not a disorder.\n",
      "\n",
      "Conclusions\n",
      "\n",
      "Application benefit\n",
      "\n",
      "To showcase the usefulness of KnowLife, we developed a health portal (http://knowlife.mpi-inf.mpg.de) that allows interactive exploration of the harvested facts and their input sources. The KnowLife portal supports a number of use cases for different information needs. A patient may wish to find out the side effects of a specific drug, by searching for the drug name and browsing the SideEffect facts and their provenance. A physician may want to \"speed read\" publications and online discussions on treatment options for an unfamiliar disease. Provenance information is vital here, as the physician would want to consider the recency and authority of the sources for certain statements. The health portal also provides a function for on-the-fly annotation of new text from publications or social media, leveraging known patterns to highlight any relations found.\n",
      "\n",
      "Future work\n",
      "\n",
      "In the future, we plan to improve the entity recognition to accommodate a wider variety of entities beyond those in UMLS. For instance, colloquial usage (meds for medicines) and composite entities (amputation of right leg) are not yet addressed. Entities within UMLS also require more sophisticated disambiguation. For instance, the text occurrence stress may be correctly distinguished between the brand name of a drug and the psychological feeling.\n",
      "\n",
      "Finally, we would like to address the challenge of mining and representing the context of harvested facts. Binary relations are often not sufficient to express medical knowledge. For example, the statement Fever is a symptom of Lupus Flare during pregnancy cannot be suitably represented by a binary fact.\n",
      "\n",
      "We plan to cope with such statements by extracting ternary and higher-arity relations, with appropriate extensions of both pattern-based extraction and consistency reasoning.\n",
      "\n",
      "Additional files\n",
      "\n",
      "Competing interests\n",
      "\n",
      "The authors declare that they have no competing interests.\n",
      "\n",
      "Authors' contributions\n",
      "\n",
      "AS developed the entity recognition and prepared the input sources. PE implemented the information extraction pipeline, integrated all components and designed the evaluation. AS and PE conducted the evaluation and drafted the manuscript. The work was advised by GW. All authors read and approved the final manuscript.\n",
      "\n",
      "References\n",
      "\n",
      "Shallow information extraction for the knowledge web\n",
      "\n",
      "Knowledge harvesting from text and web sources\n",
      "\n",
      "DBpedia - a large-scale, multilingual knowledge base extracted from Wikipedia\n",
      "\n",
      "YAGO2: A Spatially and Temporally Enhanced Knowledge Base from Wikipedia\n",
      "\n",
      "Event extraction across multiple levels of biological organization\n",
      "\n",
      "BioCreative III interactive task: An overview\n",
      "\n",
      "Corpus annotation for mining biomedical events from literature\n",
      "\n",
      "Pharmacogenomics knowledge for personalized medicine\n",
      "\n",
      "Open PHACTS: semantic interoperability for drug discovery\n",
      "\n",
      "Event extraction from trimmed dependency graphs\n",
      "\n",
      "Event extraction with complex event classification using rich features\n",
      "\n",
      "Generalizing biomedical event extraction\n",
      "\n",
      "Extraction of human kinase mutations from literature, databases and genotyping studies\n",
      "\n",
      "Classifying semantic relations in bioscience texts\n",
      "\n",
      "Extraction of semantic biomedical relations from text using conditional random fields\n",
      "\n",
      "Evaluating temporal relations in clinical text: 2012 i2b2 challenge\n",
      "\n",
      "Bravo A, Cases M, Queralt-Rosinach N, Sanz F, Furlong L. A knowledge-driven approach to extract disease-related biomarkers from the literature. BioMed Res Int. 2014. article ID: 253128.\n",
      "\n",
      "Chun HW, Tsuruoka Y, Kim JD, Shiba R, Nagata N, Hishiki T, et al. Extraction of gene-disease relations from medline using domain dictionaries and machine learning. In: Proceedings of Pacific Symposium of Biocomputing: 2006. p. 4-15.\n",
      "\n",
      "Genescene: An ontology-enhanced integration of linguistic and co-occurrence based relations in biomedical texts\n",
      "\n",
      "Semantic relations asserting the etiology of genetic diseases\n",
      "\n",
      "Crowdsourcing for bioinformatics\n",
      "\n",
      "Crowdsourcing-harnessing the masses to advance health and medicine, a systematic review\n",
      "\n",
      "Burger JD, Doughty E, Khare R, Wei C-H, Mishra R, Aberdeen J, et al.Hybrid curation of gene-mutation relations combining automated extraction and crowdsourcing. Database. 2014; 2014. article ID: bau094.\n",
      "\n",
      "Measuring crowd truth for medical relation extraction\n",
      "\n",
      "OpenDMAP: An open source, ontology-driven concept analysis engine, with applications to capturing knowledge regarding protein transport, protein interactions and cell-type-specific gene expression\n",
      "\n",
      "Text mining of protein phosphorylation information using a generalizable rule-based approach\n",
      "\n",
      "Textpresso: an ontology-based information retrieval and extraction system for biological literature\n",
      "\n",
      "PASBio: predicate-argument structures for event extraction in molecular biology\n",
      "\n",
      "Identification of new drug classification terms in textual resources\n",
      "\n",
      "Automatic acquisition of hyponyms from large text corpora\n",
      "\n",
      "The interaction of domain knowledge and linguistic structure in natural language processing: interpreting hypernymic propositions in biomedical text\n",
      "\n",
      "Sentic patterns: dependency-based rules for concept-level sentiment analysis\n",
      "\n",
      "GeneView: a comprehensive semantic search engine for PubMed\n",
      "\n",
      "dRiskKB: a large-scale disease-disease risk relationship knowledge base constructed from biomedical text\n",
      "\n",
      "Extracting patterns and relations from the World Wide Web\n",
      "\n",
      "Snowball: Extracting relations from large plain-text collections\n",
      "\n",
      "SOFIE: A self-organizing framework for information extraction\n",
      "\n",
      "Scalable knowledge harvesting with high precision and high recall\n",
      "\n",
      "Toward an architecture for never-ending language learning\n",
      "\n",
      "DIDO: A disease-determinants ontology from Web sources\n",
      "\n",
      "Bootstrapping biomedical ontologies for scientific text using NELL\n",
      "\n",
      "An overview of MetaMap: historical perspective and recent advances\n",
      "\n",
      "Which species is it? Species-driven gene name disambiguation using random walks over a mixture of adjacency matrices\n",
      "\n",
      "Word sense disambiguation in the clinical domain: a comparison of knowledge-rich and knowledge-poor unsupervised methods\n",
      "\n",
      "Gauging the Internet doctor: Ranking medical claims based on community knowledge\n",
      "\n",
      "People on drugs: Credibility of user statements in health communities\n",
      "\n",
      "Toward enhanced pharmacovigilance using patient-generated data on the Internet\n",
      "\n",
      "KnowLife: a knowledge graph for health and life sciences\n",
      "\n",
      "Fast entity recognition in biomedical text\n",
      "\n",
      "Similarity estimation techniques from rounding algorithms\n",
      "\n",
      "Min-wise independent permutations\n",
      "\n",
      "New upper bounds for maximum satisfiability\n",
      "\n",
      "Approximation algorithms for combinatorial problems\n",
      "\n",
      "Aggregating UMLS semantic types for reducing conceptual complexity\n",
      "\n",
      "The integrated disease network.\n",
      "\n",
      "The growing body of transcriptomic, proteomic, metabolomic and genomic data generated from disease states provides a great opportunity to improve our current understanding of the molecular mechanisms driving diseases and shared between diseases. The use of both clinical and molecular phenotypes will lead to better disease understanding and classification. In this study, we set out to gain novel insights into diseases and their relationships by utilising knowledge gained from system-level molecular data. We integrated different types of biological data including genome-wide association studies data, disease-chemical associations, biological pathways and Gene Ontology annotations into an Integrated Disease Network (IDN), a heterogeneous network where nodes are bio-entities and edges between nodes represent their associations. We also introduced a novel disease similarity measure to infer disease-disease associations from the IDN. Our predicted associations were systemically evaluated against the Medical Subject Heading classification and a statistical measure of disease co-occurrence in PubMed. The strong correlation between our predictions and co-occurrence associations indicated the ability of our approach to recover known disease associations. Furthermore, we presented a case study of Crohn's disease. We demonstrated that our approach not only identified well-established connections between Crohn's disease and other diseases, but also revealed new, interesting connections consistent with emerging literature. Our approach also enabled ready access to the knowledge supporting these new connections, making this a powerful approach for exploring connections between diseases.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "xml_file = \"PMC4448285.xml\"  # Replace with your BioC XML file\n",
    "full_text = extract_full_text_from_bioc(xml_file)\n",
    "\n",
    "# Print or save the full text\n",
    "print(full_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def extract_selected_sections_from_bioc(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    full_text = []\n",
    "\n",
    "    # Define the section types we want to keep\n",
    "    sections_to_keep = [\"ABSTRACT\", \"INTRO\"]\n",
    "\n",
    "    for document in root.findall(\".//document\"):\n",
    "        for passage in document.findall(\"passage\"):\n",
    "            # Get the section type from the infon key=\"section_type\"\n",
    "            section_type = passage.find(\"infon[@key='section_type']\").text if passage.find(\"infon[@key='section_type']\") else None\n",
    "            \n",
    "            # Check if the section type is one of the desired sections\n",
    "            if section_type in sections_to_keep:\n",
    "                text = passage.find(\"text\").text\n",
    "                if text:\n",
    "                    full_text.append(text.strip())\n",
    "\n",
    "    return \"\\n\\n\".join(full_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "xml_file = \"PMC4448285.xml\"  # Path to your BioC XML file\n",
    "selected_text = extract_selected_sections_from_bioc(xml_file)\n",
    "\n",
    "# Print the selected text\n",
    "print(selected_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "xml_file = \"PMC4448285.xml\"  # Replace with your BioC XML file\n",
    "sections = [\"ABSTRACT\", \"introduction\"]  # Sections you want to keep\n",
    "selected_text = extract_selected_sections_from_bioc(xml_file, sections)\n",
    "\n",
    "# Print or save the selected text\n",
    "print(selected_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded full text XML as 4448285.xml\n"
     ]
    }
   ],
   "source": [
    "# Base URL for PMC OAI-PMH\n",
    "pmc_url = f\"https://www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi?verb=GetRecord&metadataPrefix=pmc&identifier=pmcid:PMC4448285\"\n",
    "\n",
    "# Make the request to get full text XML\n",
    "response = requests.get(pmc_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(f\"PMC4448285.xml\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(response.text)\n",
    "    print(f\"Downloaded full text XML as 4448285.xml\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the full text.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing out pubtator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded full text XML as 4448285.xml\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def annotate_pmids(pmids):\n",
    "    # Define the PubTator API URL\n",
    "    pubtator_url = \"https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/biocxml\"\n",
    "\n",
    "    # Join the PMIDs into a comma-separated string\n",
    "    pmid_str = ','.join(pmids)\n",
    "\n",
    "    # Send a GET request to the API with the list of PMIDs\n",
    "    response = requests.get(pubtator_url, params={\"pmids\": pmid_str, \"full\": True})\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        with open(f\"PMC4448285.xml\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(response.text)\n",
    "        print(f\"Downloaded full text XML as 4448285.xml\")\n",
    "    # if response.status_code == 200:\n",
    "        #return response.json()  # Return the response in JSON format\n",
    "    else:\n",
    "        raise Exception(f\"Error {response.status_code}: {response.text}\")\n",
    "\n",
    "# Example usage\n",
    "pmids = [\"25133803\", \"25971816\"]\n",
    "annotations = annotate_pmids(pmids)\n",
    "\n",
    "# Display the annotated results\n",
    "import pprint\n",
    "pprint.pprint(annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bkg-review-FcnO91kN-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
