{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will be troubleshooting transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a229924dd904b67b4c14a6b986af9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0cca15f89b4dc398411df8f06c19bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195d4fd8c8a445dda1e0d83618281147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anglup/Library/Caches/pypoetry/virtualenvs/pubmed-rag-iB5Z1S4t-py3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e4f309b6a84108b98f6bfac0ba1168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 2608, 2084, 2242, 5395, 1922, 1920, 21187, 1927, 11980, 12813, 8544, 1036, 16, 1958, 2611, 2032, 12842, 1930, 8385, 1942, 17486, 18, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input = tokenizer(\"Do not meddle in the affairs of wizards, for they are subtle and quick to anger.\")\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] do not meddle in the affairs of wizards, for they are subtle and quick to anger. [SEP]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>section</th>\n",
       "      <th>sentence</th>\n",
       "      <th>pmid</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>date</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TITLE</td>\n",
       "      <td>KnowLife: a versatile approach for constructin...</td>\n",
       "      <td>25971816</td>\n",
       "      <td>PMC4448285</td>\n",
       "      <td>2015-05-14T00:00:00Z</td>\n",
       "      <td>Ernst P and Siu A and Weikum G</td>\n",
       "      <td>BMC Bioinformatics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ABSTRACT</td>\n",
       "      <td>Background</td>\n",
       "      <td>25971816</td>\n",
       "      <td>PMC4448285</td>\n",
       "      <td>2015-05-14T00:00:00Z</td>\n",
       "      <td>Ernst P and Siu A and Weikum G</td>\n",
       "      <td>BMC Bioinformatics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ABSTRACT</td>\n",
       "      <td>Biomedical knowledge bases (KB's) have become ...</td>\n",
       "      <td>25971816</td>\n",
       "      <td>PMC4448285</td>\n",
       "      <td>2015-05-14T00:00:00Z</td>\n",
       "      <td>Ernst P and Siu A and Weikum G</td>\n",
       "      <td>BMC Bioinformatics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ABSTRACT</td>\n",
       "      <td>Results</td>\n",
       "      <td>25971816</td>\n",
       "      <td>PMC4448285</td>\n",
       "      <td>2015-05-14T00:00:00Z</td>\n",
       "      <td>Ernst P and Siu A and Weikum G</td>\n",
       "      <td>BMC Bioinformatics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ABSTRACT</td>\n",
       "      <td>We address these three limitations by a versat...</td>\n",
       "      <td>25971816</td>\n",
       "      <td>PMC4448285</td>\n",
       "      <td>2015-05-14T00:00:00Z</td>\n",
       "      <td>Ernst P and Siu A and Weikum G</td>\n",
       "      <td>BMC Bioinformatics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   section                                           sentence  \\\n",
       "0      0     TITLE  KnowLife: a versatile approach for constructin...   \n",
       "1      1  ABSTRACT                                         Background   \n",
       "2      2  ABSTRACT  Biomedical knowledge bases (KB's) have become ...   \n",
       "3      3  ABSTRACT                                            Results   \n",
       "4      4  ABSTRACT  We address these three limitations by a versat...   \n",
       "\n",
       "       pmid       pmcid                  date                         authors  \\\n",
       "0  25971816  PMC4448285  2015-05-14T00:00:00Z  Ernst P and Siu A and Weikum G   \n",
       "1  25971816  PMC4448285  2015-05-14T00:00:00Z  Ernst P and Siu A and Weikum G   \n",
       "2  25971816  PMC4448285  2015-05-14T00:00:00Z  Ernst P and Siu A and Weikum G   \n",
       "3  25971816  PMC4448285  2015-05-14T00:00:00Z  Ernst P and Siu A and Weikum G   \n",
       "4  25971816  PMC4448285  2015-05-14T00:00:00Z  Ernst P and Siu A and Weikum G   \n",
       "\n",
       "              journal  \n",
       "0  BMC Bioinformatics  \n",
       "1  BMC Bioinformatics  \n",
       "2  BMC Bioinformatics  \n",
       "3  BMC Bioinformatics  \n",
       "4  BMC Bioinformatics  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing data\n",
    "fpath = '/Users/anglup/GitHub/pubmed-rag/notebooks/biocjson/df_25971816.csv'\n",
    "\n",
    "test_df = pd.read_csv(fpath)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>section</th>\n",
       "      <th>sentence</th>\n",
       "      <th>pmid</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>date</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>title</td>\n",
       "      <td>Heterogeneous Network Edge Prediction: A Data ...</td>\n",
       "      <td>26158728</td>\n",
       "      <td>PMC4497619</td>\n",
       "      <td>2015-07-09 00:00:00+00:00</td>\n",
       "      <td>Himmelstein DS and Baranzini SE</td>\n",
       "      <td>PLoS Comput Biol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The first decade of Genome Wide Association St...</td>\n",
       "      <td>26158728</td>\n",
       "      <td>PMC4497619</td>\n",
       "      <td>2015-07-09 00:00:00+00:00</td>\n",
       "      <td>Himmelstein DS and Baranzini SE</td>\n",
       "      <td>PLoS Comput Biol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Author Summary.</td>\n",
       "      <td>26158728</td>\n",
       "      <td>PMC4497619</td>\n",
       "      <td>2015-07-09 00:00:00+00:00</td>\n",
       "      <td>Himmelstein DS and Baranzini SE</td>\n",
       "      <td>PLoS Comput Biol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>abstract</td>\n",
       "      <td>For complex human diseases, identifying the ge...</td>\n",
       "      <td>26158728</td>\n",
       "      <td>PMC4497619</td>\n",
       "      <td>2015-07-09 00:00:00+00:00</td>\n",
       "      <td>Himmelstein DS and Baranzini SE</td>\n",
       "      <td>PLoS Comput Biol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>intro</td>\n",
       "      <td>Introduction.</td>\n",
       "      <td>26158728</td>\n",
       "      <td>PMC4497619</td>\n",
       "      <td>2015-07-09 00:00:00+00:00</td>\n",
       "      <td>Himmelstein DS and Baranzini SE</td>\n",
       "      <td>PLoS Comput Biol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   section                                           sentence  \\\n",
       "0      0     title  Heterogeneous Network Edge Prediction: A Data ...   \n",
       "1      1  abstract  The first decade of Genome Wide Association St...   \n",
       "2      2  abstract                                    Author Summary.   \n",
       "3      3  abstract  For complex human diseases, identifying the ge...   \n",
       "4      4     intro                                      Introduction.   \n",
       "\n",
       "       pmid       pmcid                      date  \\\n",
       "0  26158728  PMC4497619 2015-07-09 00:00:00+00:00   \n",
       "1  26158728  PMC4497619 2015-07-09 00:00:00+00:00   \n",
       "2  26158728  PMC4497619 2015-07-09 00:00:00+00:00   \n",
       "3  26158728  PMC4497619 2015-07-09 00:00:00+00:00   \n",
       "4  26158728  PMC4497619 2015-07-09 00:00:00+00:00   \n",
       "\n",
       "                           authors           journal  \n",
       "0  Himmelstein DS and Baranzini SE  PLoS Comput Biol  \n",
       "1  Himmelstein DS and Baranzini SE  PLoS Comput Biol  \n",
       "2  Himmelstein DS and Baranzini SE  PLoS Comput Biol  \n",
       "3  Himmelstein DS and Baranzini SE  PLoS Comput Biol  \n",
       "4  Himmelstein DS and Baranzini SE  PLoS Comput Biol  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning?\n",
    "# read in example\n",
    "df_test = pd.read_csv('biocjson/df_26158728.csv')\n",
    "# lower case section names\n",
    "df_test['section'] = df_test['section'].str.lower().str.strip()\n",
    "# pmids to object\n",
    "df_test['pmid'] = df_test['pmid'].astype(str)\n",
    "df_test['date'] = pd.to_datetime(df_test['date'])\n",
    "# also stripping sentences in case?\n",
    "df_test['sentence'] = df_test['sentence'].str.strip()\n",
    "\n",
    "punctuations = ('!',',','.','?',',','\"', \"'\")\n",
    "# lol adding a . to the end for now?\n",
    "df_test['sentence'] = np.where(df_test['sentence'].str.endswith(punctuations), df_test['sentence'], df_test['sentence']+'.')\n",
    "\n",
    "# check\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which sections to keep? \n",
    "keep_sections = ['title', 'abstract', 'intro', 'results', 'discuss', 'methods']\n",
    "\n",
    "# filter \n",
    "df_filtered = df_test[df_test['section'].isin(keep_sections)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>section</th>\n",
       "      <th>sentence</th>\n",
       "      <th>pmid</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>date</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>intro</td>\n",
       "      <td>Introduction.</td>\n",
       "      <td>26158728</td>\n",
       "      <td>PMC4497619</td>\n",
       "      <td>2015-07-09 00:00:00+00:00</td>\n",
       "      <td>Himmelstein DS and Baranzini SE</td>\n",
       "      <td>PLoS Comput Biol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>results</td>\n",
       "      <td>Results.</td>\n",
       "      <td>26158728</td>\n",
       "      <td>PMC4497619</td>\n",
       "      <td>2015-07-09 00:00:00+00:00</td>\n",
       "      <td>Himmelstein DS and Baranzini SE</td>\n",
       "      <td>PLoS Comput Biol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>discuss</td>\n",
       "      <td>Discussion.</td>\n",
       "      <td>26158728</td>\n",
       "      <td>PMC4497619</td>\n",
       "      <td>2015-07-09 00:00:00+00:00</td>\n",
       "      <td>Himmelstein DS and Baranzini SE</td>\n",
       "      <td>PLoS Comput Biol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>methods</td>\n",
       "      <td>Methods.</td>\n",
       "      <td>26158728</td>\n",
       "      <td>PMC4497619</td>\n",
       "      <td>2015-07-09 00:00:00+00:00</td>\n",
       "      <td>Himmelstein DS and Baranzini SE</td>\n",
       "      <td>PLoS Comput Biol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>methods</td>\n",
       "      <td>Nodes.</td>\n",
       "      <td>26158728</td>\n",
       "      <td>PMC4497619</td>\n",
       "      <td>2015-07-09 00:00:00+00:00</td>\n",
       "      <td>Himmelstein DS and Baranzini SE</td>\n",
       "      <td>PLoS Comput Biol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>methods</td>\n",
       "      <td>Associations.</td>\n",
       "      <td>26158728</td>\n",
       "      <td>PMC4497619</td>\n",
       "      <td>2015-07-09 00:00:00+00:00</td>\n",
       "      <td>Himmelstein DS and Baranzini SE</td>\n",
       "      <td>PLoS Comput Biol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  section       sentence      pmid       pmcid  \\\n",
       "4       4    intro  Introduction.  26158728  PMC4497619   \n",
       "11     11  results       Results.  26158728  PMC4497619   \n",
       "60     60  discuss    Discussion.  26158728  PMC4497619   \n",
       "66     66  methods       Methods.  26158728  PMC4497619   \n",
       "73     73  methods         Nodes.  26158728  PMC4497619   \n",
       "75     75  methods  Associations.  26158728  PMC4497619   \n",
       "\n",
       "                        date                          authors  \\\n",
       "4  2015-07-09 00:00:00+00:00  Himmelstein DS and Baranzini SE   \n",
       "11 2015-07-09 00:00:00+00:00  Himmelstein DS and Baranzini SE   \n",
       "60 2015-07-09 00:00:00+00:00  Himmelstein DS and Baranzini SE   \n",
       "66 2015-07-09 00:00:00+00:00  Himmelstein DS and Baranzini SE   \n",
       "73 2015-07-09 00:00:00+00:00  Himmelstein DS and Baranzini SE   \n",
       "75 2015-07-09 00:00:00+00:00  Himmelstein DS and Baranzini SE   \n",
       "\n",
       "             journal  \n",
       "4   PLoS Comput Biol  \n",
       "11  PLoS Comput Biol  \n",
       "60  PLoS Comput Biol  \n",
       "66  PLoS Comput Biol  \n",
       "73  PLoS Comput Biol  \n",
       "75  PLoS Comput Biol  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[[len(x)==1 for x in df_filtered['sentence'].str.split(' ', )]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>section</th>\n",
       "      <th>sentence</th>\n",
       "      <th>pmid</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>date</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The first decade of Genome Wide Association St...</td>\n",
       "      <td>26158728</td>\n",
       "      <td>PMC4497619</td>\n",
       "      <td>2015-07-09 00:00:00+00:00</td>\n",
       "      <td>Himmelstein DS and Baranzini SE</td>\n",
       "      <td>PLoS Comput Biol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Author Summary.</td>\n",
       "      <td>26158728</td>\n",
       "      <td>PMC4497619</td>\n",
       "      <td>2015-07-09 00:00:00+00:00</td>\n",
       "      <td>Himmelstein DS and Baranzini SE</td>\n",
       "      <td>PLoS Comput Biol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>abstract</td>\n",
       "      <td>For complex human diseases, identifying the ge...</td>\n",
       "      <td>26158728</td>\n",
       "      <td>PMC4497619</td>\n",
       "      <td>2015-07-09 00:00:00+00:00</td>\n",
       "      <td>Himmelstein DS and Baranzini SE</td>\n",
       "      <td>PLoS Comput Biol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   section                                           sentence  \\\n",
       "1      1  abstract  The first decade of Genome Wide Association St...   \n",
       "2      2  abstract                                    Author Summary.   \n",
       "3      3  abstract  For complex human diseases, identifying the ge...   \n",
       "\n",
       "       pmid       pmcid                      date  \\\n",
       "1  26158728  PMC4497619 2015-07-09 00:00:00+00:00   \n",
       "2  26158728  PMC4497619 2015-07-09 00:00:00+00:00   \n",
       "3  26158728  PMC4497619 2015-07-09 00:00:00+00:00   \n",
       "\n",
       "                           authors           journal  \n",
       "1  Himmelstein DS and Baranzini SE  PLoS Comput Biol  \n",
       "2  Himmelstein DS and Baranzini SE  PLoS Comput Biol  \n",
       "3  Himmelstein DS and Baranzini SE  PLoS Comput Biol  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.groupby('section').get_group('abstract').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_sections(\n",
    "        df:pd.DataFrame, \n",
    "        out_path:str, \n",
    "        prefix:str='sectioned_'\n",
    "    )->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given df from passages_to_df(), collapses the section into a single text block.\n",
    "\n",
    "    PARAMS\n",
    "    -----\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ### PRECONDITIONS\n",
    "    # dtypes\n",
    "    assert isinstance(df, pd.DataFrame), f'df must be a dataframe: {df}'\n",
    "    #assert_path(out_path)\n",
    "    assert isinstance(prefix, str), \\\n",
    "        f'prefix must be a string: {prefix}'\n",
    "    # other\n",
    "    assert 'section' in df.columns, \\\n",
    "        f'\"section\" column does not exist in df columns: {df.columns}'\n",
    "\n",
    "    ### MAIN FUNCTION\n",
    "\n",
    "    # group by section\n",
    "    grouped = df.groupby('section')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\n",
      "discuss\n",
      "intro\n",
      "methods\n",
      "results\n",
      "title\n"
     ]
    }
   ],
   "source": [
    "ya = {}\n",
    "\n",
    "for each in df_filtered.groupby('section'):\n",
    "\n",
    "    # verbose\n",
    "    print(each[0])\n",
    "\n",
    "    section_rows = each[1].sort_values(by='index', ascending=True)\n",
    "\n",
    "    section_rows['text'] = (' '.join(section_rows['sentence']))\n",
    "\n",
    "    section_rows = section_rows.drop_duplicates(subset=['text', 'section', ])\n",
    "\n",
    "    section_rows = section_rows.drop(['index', 'sentence'], axis=1)\n",
    "\n",
    "    section_rows = section_rows.reset_index(drop=True)\n",
    "\n",
    "    ya[each[0]] = section_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapsed = pd.concat(ya, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = collapsed.loc[3, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 2860, 18, 7809, 12977, 18, 2052, 2161, 1982, 4871, 2007, 1920, 16489, 1038, 6540, 3043, 7353, 1990, 2616, 3297, 2441, 4478, 7, 2119, 17, 3472, 14743, 18, 8538, 5849, 18, 2038, 7000, 43, 3335, 6465, 1930, 4437, 4585, 4187, 8511, 1958, 7479, 8538, 5849, 18, 3189, 6378, 12414, 16, 8538, 5849, 3149, 1927, 6263, 7951, 2007, 11473, 16, 5574, 1988, 1925, 3281, 5880, 4757, 16737, 2601, 18, 6267, 2601, 2105, 13208, 1920, 6925, 1927, 14866, 7905, 16, 3417, 8269, 2601, 2105, 13208, 1920, 6925, 1927, 3303, 7905, 18, 8269, 3584, 2032, 8842, 1927, 43, 4585, 6267, 2601, 16, 2758, 6267, 2601, 16, 6925, 12, 1942, 9290, 2192, 3137, 8269, 3584, 15031, 1920, 2841, 6267, 3584, 13, 16, 1930, 4924, 12, 7201, 1958, 2321, 6554, 1930, 3075, 6264, 1919, 8269, 3584, 13, 18, 1920, 8124, 16737, 2144, 3584, 1930, 6641, 2209, 2362, 6267, 1930, 8269, 16, 4073, 13874, 16, 1956, 2496, 3980, 2601, 18, 1920, 5880, 4757, 6999, 2112, 1998, 5960, 1966, 43, 4982, 7600, 1927, 6267, 3584, 7951, 2007, 8269, 3584, 18, 2469, 17714, 1942, 2052, 4982, 1927, 3584, 16, 2038, 2485, 1920, 9328, 2416, 11, 5880, 11, 18, 5880, 14644, 30, 6043, 26374, 1036, 1922, 2555, 2778, 30, 3149, 1927, 5880, 11873, 7980, 7951, 2007, 5880, 1919, 2286, 18, 1922, 43, 8538, 3504, 16, 2362, 2450, 16, 43, 4696, 1927, 11473, 1956, 3059, 11213, 2141, 6263, 16, 8852, 1942, 43, 5880, 9112, 7479, 1920, 2601, 1927, 2450, 18, 43, 2450, 11, 61, 5880, 9112, 1977, 1920, 4696, 1927, 5880, 1919, 2286, 3980, 1942, 1988, 2450, 11, 61, 11473, 18, 1920, 3216, 5880, 9112, 1036, 2651, 43, 8538, 3504, 2112, 1998, 18230, 13503, 2007, 27480, 1941, 1920, 5880, 8854, 18, 2038, 7397, 2052, 6465, 1966, 1925, 8032, 17, 10823, 2230, 3170, 1922, 25593, 1930, 10314, 1920, 3864, 8511, 21997, 3940, 18, 6603, 2032, 3294, 1942, 7233, 4127, 16, 2485, 16, 2014, 4672, 1942, 1920, 4187, 16, 2596, 1920, 6302, 18868, 12, 11582, 30, 19, 19, 24913, 18, 2008, 19, 6781, 1980, 22629, 19, 21997, 3940, 13, 18, 3504, 9469, 18, 1920, 3063, 6151, 16, 1930, 5566, 1920, 5880, 1919, 2286, 1930, 5880, 11873, 7980, 3816, 1941, 2342, 3504, 16, 1985, 3790, 17560, 2454, 1990, 43, 6766, 2706, 1920, 2894, 3879, 30, 21, 13, 3455, 30, 8043, 1942, 2616, 6559, 31, 2149, 4923, 1930, 1925, 5419, 12491, 17, 4013, 2192, 7198, 15196, 1930, 7198, 23371, 18, 1922, 2673, 2919, 16, 3455, 8103, 8715, 1920, 6125, 1927, 43, 9465, 5880, 1919, 2106, 18, 1958, 3534, 16, 2038, 16640, 13314, 17, 2454, 2573, 4852, 2810, 1942, 1925, 22172, 2573, 13314, 18048, 16, 1930, 2038, 16640, 2573, 12665, 2810, 1942, 2149, 4783, 4622, 1958, 14403, 3902, 18, 1958, 3063, 5880, 1919, 2286, 16, 2038, 11189, 1942, 8702, 1920, 4554, 3455, 7965, 1922, 1988, 3418, 18, 22, 13, 1964, 28553, 12039, 1999, 30, 7278, 7347, 19708, 1930, 12505, 2115, 31, 9225, 1942, 4642, 19089, 2168, 2062, 31, 2486, 6974, 31, 19218, 1942, 13257, 12, 19706, 1919, 13, 2333, 31, 3294, 1927, 18519, 2470, 1964, 2517, 28192, 3249, 18, 23, 13, 9984, 30, 4949, 3418, 17, 2487, 6745, 3999, 2193, 5614, 13334, 1988, 9491, 5353, 18, 2679, 3299, 3719, 2162, 3024, 9253, 12840, 16, 2310, 13766, 7285, 1922, 5209, 1982, 14337, 16839, 1958, 2342, 2998, 18, 24, 13, 5479, 2828, 16, 13564, 9546, 30254, 19044, 1024, 1927, 7256, 30, 19249, 16, 1922, 12405, 16, 3086, 6082, 1927, 11985, 3436, 3137, 2428, 1927, 3933, 7778, 18, 2428, 1927, 1920, 10663, 9335, 1927, 3933, 7778, 3951, 1920, 3843, 16, 10815, 16, 13557, 16, 6310, 2225, 16, 3074, 2225, 16, 2024, 1930, 2960, 5901, 16, 1930, 3037, 2225, 18, 22373, 2144, 12943, 16, 2038, 6714, 1966, 3086, 6151, 1966, 3216, 2651, 2342, 8216, 4747, 6995, 10227, 18, 6263, 18, 2213, 17, 5804, 2628, 12, 6080, 2230, 13, 1985, 5210, 2037, 1920, 7175, 15895, 5039, 18, 6151, 1985, 9225, 1942, 7175, 15895, 4430, 3454, 2359, 17530, 12, 17307, 14834, 1985, 8397, 1922, 1920, 3238, 30, 4871, 16, 2555, 16, 26023, 1036, 13, 2014, 10426, 24434, 18, 2573, 6263, 12, 8226, 1930, 11461, 2230, 13, 1985, 4208, 2037, 1920, 2573, 13314, 12, 2608, 13, 18, 2810, 1942, 1920, 3892, 2529, 1927, 3902, 1956, 12385, 16, 4494, 2573, 12229, 1985, 11062, 9225, 1942, 1920, 2608, 12, 20800, 2230, 13, 18, 3878, 1985, 4208, 2037, 1920, 3022, 10249, 1019, 2960, 13314, 12, 8626, 1037, 13, 18, 2444, 3878, 1956, 30085, 2294, 1985, 3063, 12180, 8507, 7084, 18, 6263, 1958, 1920, 2607, 17355, 11526, 1014, 5880, 11873, 7980, 1985, 4103, 17518, 2037, 1920, 3272, 9983, 5039, 4671, 24, 18, 20, 18, 2136, 17355, 11526, 1014, 16471, 1985, 3063, 5574, 2690, 1988, 1985, 12636, 3441, 1927, 2303, 16471, 18, 1958, 3534, 16, 11, 8351, 30, 5219, 2359, 5704, 11, 1982, 1920, 13030, 1927, 2288, 2054, 15064, 2879, 16471, 12, 11, 8351, 30, 14084, 4845, 11, 1930, 11, 8351, 30, 3213, 2991, 4845, 11, 13, 1930, 1982, 2955, 5450, 18, 3902, 1985, 5947, 11062, 2460, 2119, 6118, 3147, 1942, 11985, 18, 1920, 11, 13513, 11, 1930, 11, 28396, 11, 6118, 1985, 2084, 3063, 1966, 11985, 6263, 16, 3328, 2611, 2608, 2084, 2105, 5169, 10698, 10857, 2192, 7210, 3902, 18, 5253, 18, 2573, 17, 2359, 5253, 1985, 5210, 2037, 1920, 12385, 13649, 16, 43, 2059, 29526, 1927, 12385, 5253, 2597, 58, 32, 2119, 17, 25, 18, 2561, 16, 5253, 1985, 22439, 2007, 2573, 18, 12385, 13649, 6568, 1985, 9076, 1942, 3599, 2991, 13314, 12, 8485, 1037, 13, 4430, 2193, 7084, 1036, 4152, 2007, 1920, 6785, 13146, 5381, 18, 5253, 7084, 1942, 3137, 8485, 1037, 4430, 1985, 5450, 1942, 11134, 3567, 17, 4629, 2351, 18, 2038, 11062, 9225, 8485, 1037, 1942, 2608, 4430, 12, 5195, 3063, 1922, 1920, 2608, 1966, 3567, 17, 12229, 13, 1930, 10633, 2362, 2608, 2576, 1956, 2496, 5253, 18, 5253, 1985, 5947, 1966, 3108, 2149, 2014, 2330, 17, 5203, 16, 2597, 15547, 2288, 9761, 21660, 2149, 17, 5203, 3642, 18, 2561, 16, 58, 32, 33, 25, 14, 2119, 17, 28, 3980, 1942, 58, 32, 33, 20, 18, 2914, 2256, 11180, 7970, 1958, 2340, 7068, 5768, 12, 1925, 12543, 5199, 4124, 1958, 1920, 2529, 1927, 3484, 6084, 3747, 2007, 2501, 12385, 13, 18, 2812, 16, 43, 6081, 2983, 3081, 12, 10898, 2321, 2919, 1930, 3562, 13, 1927, 21, 16, 3240, 1982, 3414, 16, 3328, 2351, 4535, 2052, 3081, 2032, 18757, 3842, 1919, 30, 51, 18, 47, 18, 2967, 8117, 5253, 2032, 2253, 3205, 2254, 2084, 1942, 1998, 7198, 30, 1958, 1920, 4827, 1927, 6228, 2495, 3081, 7326, 5384, 7696, 1942, 14150, 2796, 2573, 10383, 18, 2949, 17, 6084, 1985, 6304, 11883, 30, 3451, 17422, 1920, 9263, 6084, 2032, 7696, 1942, 14958, 30, 10931, 2037, 1920, 8243, 2202, 14790, 18, 11883, 1985, 3561, 1958, 2362, 2949, 17, 6821, 2007, 2849, 1920, 2498, 20536, 2156, 7671, 1930, 5863, 6084, 2597, 60, 22, 34, 20, 18, 25, 1930, 12140, 18411, 1036, 1942, 1920, 4560, 7827, 24225, 18, 5253, 1985, 12011, 2007, 5203, 16, 11404, 1990, 2894, 4164, 30, 2149, 19, 2330, 5203, 16, 58, 17, 3113, 12, 2330, 1942, 2149, 13, 16, 1930, 3169, 15895, 1012, 18, 1922, 3238, 1927, 5203, 16, 5253, 1985, 17389, 2007, 2310, 11883, 2460, 2573, 17, 2487, 6971, 12, 6934, 2230, 13, 18, 2007, 22308, 5253, 2460, 6971, 16, 5253, 2037, 3137, 2351, 22260, 1920, 2841, 5030, 2733, 1985, 20481, 12, 4062, 2095, 13, 18, 43, 6730, 1982, 5947, 1966, 2149, 17, 5203, 2647, 2967, 1927, 2496, 7895, 5253, 1985, 2149, 17, 5203, 1930, 2330, 17, 5203, 7631, 18, 1958, 2362, 2573, 17, 2487, 6971, 16, 2038, 11189, 1942, 3512, 43, 3065, 2359, 18, 1920, 3065, 2359, 1982, 8397, 1922, 1920, 2894, 3238, 30, 21, 13, 1920, 5754, 6799, 17, 2568, 2359, 31, 22, 13, 1920, 3165, 2359, 1958, 1925, 27911, 7245, 2949, 17, 6821, 31, 23, 13, 1920, 5754, 6799, 17, 2568, 2359, 1958, 1925, 27911, 7245, 2949, 17, 6821, 12, 1922, 1920, 3087, 1927, 8984, 2628, 13, 31, 24, 13, 1920, 5754, 6799, 17, 2568, 2359, 1927, 1920, 2501, 6863, 2353, 1930, 5863, 2628, 18, 5983, 22, 17, 24, 1985, 5116, 1990, 2362, 3279, 3816, 1941, 1920, 6971, 16, 1922, 3238, 1927, 5203, 16, 4801, 43, 2957, 2359, 8397, 1966, 3065, 18, 6971, 2597, 22499, 1982, 13902, 1945, 19708, 2014, 2597, 2239, 2628, 1985, 10418, 2811, 2084, 7130, 43, 3065, 2359, 18, 2136, 2447, 17, 3065, 2628, 30, 2628, 1988, 1985, 6799, 17, 2568, 16, 8984, 1920, 2949, 17, 6821, 16, 2014, 6183, 2353, 2014, 5863, 2037, 1920, 2949, 17, 6821, 30, 1985, 3311, 4067, 18, 8673, 16, 3006, 6118, 1927, 7078, 5253, 1985, 7000, 30, 2149, 17, 5203, 3065, 16, 2149, 17, 5203, 4067, 16, 2330, 17, 5203, 3065, 16, 1930, 2330, 17, 5203, 4067, 12, 8357, 2230, 13, 18, 2038, 10336, 1988, 2342, 3065, 2359, 10452, 1958, 2362, 6971, 4972, 1920, 2957, 9263, 2359, 5061, 1958, 1920, 3279, 18, 1942, 4482, 1920, 7523, 1927, 2052, 7235, 16, 2038, 3747, 1920, 3604, 1927, 2342, 8677, 7555, 2193, 2362, 6891, 1927, 3279, 1966, 15196, 12, 13808, 2095, 13, 18, 1958, 2321, 5203, 2428, 16, 3065, 5253, 29024, 4067, 5253, 3783, 2342, 2417, 20588, 10278, 2019, 4628, 3903, 9263, 2628, 1966, 3065, 18, 2406, 16, 1958, 2149, 17, 5203, 4067, 5253, 16, 1920, 11826, 1994, 5557, 1919, 20, 18, 5446, 16, 2154, 2578, 3211, 2037, 3137, 9263, 2628, 2079, 6971, 2014, 4628, 3903, 12168, 9263, 2628, 1966, 4067, 18, 1920, 3604, 6859, 2037, 2149, 1942, 2330, 5203, 5253, 1982, 4010, 16, 16759, 1942, 43, 10719, 13509, 2152, 1927, 7198, 1954, 2899, 6971, 1922, 1920, 12385, 13649, 2469, 58, 34, 22048, 2930, 17, 28, 2014, 2983, 3081, 15867, 4535, 5672, 18, 2213, 3719, 18, 3841, 2213, 17, 2213, 3719, 12, 13808, 2230, 13, 1985, 5210, 2037, 13439, 19906, 26754, 2369, 18, 20, 16, 43, 2059, 29526, 1927, 2461, 3065, 2835, 8506, 18, 1920, 13439, 19906, 26754, 1982, 7078, 1956, 12481, 1997, 1980, 1942, 14450, 2697, 1942, 2628, 16, 7989, 2213, 5048, 16, 1930, 11637, 1021, 19479, 14992, 18, 2960, 17, 2487, 2359, 2294, 18, 2960, 17, 2487, 2359, 2294, 2428, 12, 16085, 2230, 13, 1985, 5210, 2037, 1920, 9005, 1038, 2359, 2294, 13589, 18, 6801, 1956, 1920, 5469, 23745, 1019, 17, 5766, 1930, 13564, 3456, 1952, 17, 8303, 2294, 2851, 16, 4044, 16, 5517, 1015, 6885, 1985, 9076, 1942, 2641, 16, 30375, 7175, 15895, 2628, 1930, 5686, 3878, 1985, 11062, 9225, 1930, 9076, 1942, 5517, 8626, 1037, 4430, 18, 1958, 2321, 7309, 1036, 16, 1920, 12690, 2667, 1982, 2251, 1942, 3361, 2294, 2851, 18, 1920, 3968, 5170, 2119, 1927, 2294, 3113, 1982, 2251, 1966, 1920, 4683, 4164, 1958, 7691, 8269, 6125, 18, 2573, 5363, 18, 2573, 5363, 1982, 3561, 1958, 1920, 5517, 3878, 1956, 2294, 5554, 12, 16775, 2230, 13, 18, 4431, 2081, 17, 6564, 1982, 2251, 1942, 2634, 3053, 43, 2960, 1977, 4218, 2007, 43, 2573, 18, 2038, 2251, 3725, 2255, 25, 18, 20, 1942, 5869, 60, 17, 14628, 3888, 2192, 3878, 1930, 3902, 6711, 3053, 2288, 4430, 4807, 4084, 1922, 15406, 17169, 2253, 2254, 2962, 1998, 4100, 2007, 10345, 18, 2608, 4430, 1958, 3902, 1956, 12385, 1930, 8626, 1037, 3878, 1956, 2294, 5554, 1985, 11062, 9225, 1942, 1920, 11, 3933, 20437, 11, 20179, 2251, 2007, 3725, 2255, 18, 1920, 60, 17, 14628, 3593, 1982, 2251, 1966, 1920, 4683, 4164, 1958, 10474, 1007, 8269, 6125, 18, 5961, 14964, 11789, 18, 1920, 23284, 5880, 9112, 17, 2454, 13160, 1977, 2450, 6500, 12, 3808, 13, 30, 1920, 2529, 1927, 14903, 16, 1927, 43, 9296, 5880, 9112, 16, 2192, 43, 4585, 1930, 2758, 6267, 18, 2406, 16, 3808, 3731, 2084, 6278, 1958, 1920, 5064, 1927, 4982, 7911, 4231, 1920, 2450, 18, 14903, 27480, 1941, 2149, 17, 4647, 6263, 2832, 5042, 1958, 43, 3103, 7717, 1927, 1920, 3808, 16, 4281, 2149, 17, 4647, 6263, 5467, 7479, 43, 12186, 4949, 2014, 7715, 2182, 14866, 1956, 5082, 12840, 2971, 18, 1920, 2555, 2778, 3747, 2980, 11789, 1988, 3951, 43, 3808, 26475, 1942, 6278, 1958, 7911, 1930, 2568, 1988, 5766, 2450, 6500, 12, 13585, 13, 2593, 4534, 18, 1920, 26475, 1958, 13585, 22875, 1920, 2529, 1927, 14903, 2037, 1920, 4585, 1942, 2967, 2758, 5390, 1920, 2529, 1927, 14903, 2037, 2967, 2758, 1942, 1920, 4585, 18, 2597, 55, 1977, 1920, 5880, 9112, 16, 61, 1977, 1920, 4585, 6267, 16, 62, 1977, 1920, 2758, 6267, 16, 61, 55, 1977, 1920, 2735, 1927, 6263, 3980, 1942, 1920, 4585, 5880, 11873, 3695, 1927, 55, 16, 1930, 62, 55, 1977, 1920, 2735, 1927, 6263, 3980, 1942, 1920, 2758, 5880, 11873, 3695, 1927, 55, 18, 2038, 14103, 1920, 2967, 4585, 19, 2758, 5658, 1942, 14689, 1920, 2288, 10279, 4075, 18, 2406, 16, 12473, 1920, 3808, 2007, 43, 26475, 1977, 2300, 3160, 1919, 2882, 2362, 2450, 3816, 1941, 1920, 3808, 28276, 43, 4493, 4647, 7970, 18, 2647, 2288, 14903, 30, 2340, 27480, 1941, 2444, 2149, 17, 4647, 6263, 1930, 2340, 27480, 1941, 2444, 2330, 17, 4647, 6263, 30, 3816, 1021, 1920, 3808, 16, 1920, 3504, 7510, 1920, 2149, 17, 4647, 2450, 2832, 8914, 13811, 2606, 1920, 13585, 26475, 1930, 18557, 1035, 1920, 5100, 1927, 1920, 2330, 17, 4647, 2450, 4281, 2496, 4896, 18, 2955, 16, 2038, 3530, 1920, 4647, 17, 7370, 2450, 6500, 12, 8927, 7693, 13, 2154, 9864, 3292, 7987, 1036, 2362, 2450, 2192, 43, 4585, 1930, 2758, 6267, 18, 2362, 2450, 17561, 43, 2450, 17, 4647, 4863, 12, 3203, 1034, 13, 3561, 2007, 30, 21, 13, 21737, 2136, 5880, 1919, 2106, 17, 2487, 6429, 4231, 1920, 2450, 12, 46, 2450, 13, 16, 2597, 2362, 8269, 3816, 1941, 1920, 2450, 7624, 2288, 6429, 31, 22, 13, 15382, 2362, 4647, 1942, 1920, 17, 65, 4215, 16, 2597, 65, 34, 33, 20, 1930, 1977, 6043, 1920, 30135, 26864, 31, 23, 13, 23761, 2136, 26864, 23682, 6429, 1942, 4307, 1920, 3203, 1034, 18, 1920, 8927, 7693, 22875, 1920, 3578, 1927, 3203, 2523, 18, 3365, 2095, 6921, 1930, 5941, 1958, 43, 3737, 8418, 1927, 1920, 8927, 7693, 18, 10112, 4809, 2998, 18, 2450, 20292, 17788, 1990, 5937, 6933, 4165, 1942, 5660, 10027, 2946, 2133, 3050, 3642, 2037, 4075, 3980, 1942, 6360, 4493, 5880, 9112, 1036, 18, 2406, 16, 17293, 1956, 7380, 15196, 1942, 12056, 2342, 2322, 1930, 43, 3103, 2529, 1927, 4075, 16, 2038, 9575, 43, 6314, 2301, 2998, 16, 2154, 8267, 1942, 5531, 1920, 2338, 22772, 2104, 25630, 11590, 1942, 4165, 18, 26116, 16433, 4517, 7778, 16, 43, 12491, 6834, 1927, 2338, 22772, 2104, 18, 2038, 10692, 1920, 10159, 3254, 4778, 1927, 26116, 16, 2154, 1977, 8536, 7397, 1958, 6933, 4165, 2007, 1920, 60, 20458, 14278, 8511, 18, 6314, 2301, 6933, 4165, 5474, 43, 5817, 16, 18279, 16, 4308, 1920, 4568, 1927, 26116, 18, 2038, 8944, 18279, 7555, 1958, 2362, 2322, 3977, 18, 2193, 2119, 17, 3728, 3567, 17, 6635, 1930, 1920, 6, 2340, 17, 2970, 17, 4622, 6, 8728, 1942, 12208, 1920, 5419, 18279, 2037, 4946, 2152, 16, 2038, 9575, 43, 11375, 2998, 4609, 1942, 4625, 2338, 22772, 2104, 18, 1990, 1920, 4096, 2735, 1927, 2359, 17, 2573, 5803, 16, 2038, 8944, 1920, 10159, 3254, 10845, 5817, 12, 4595, 13, 16, 1920, 8927, 7693, 30135, 26864, 12, 65, 13, 16, 1930, 2288, 8269, 6125, 9761, 18, 2561, 16, 2038, 8944, 4595, 1930, 65, 1990, 1920, 2036, 4075, 6098, 5880, 9112, 1036, 2811, 2084, 3951, 4683, 17, 3100, 5880, 1919, 2286, 18, 1958, 2362, 3921, 1927, 4595, 1930, 65, 16, 2038, 3561, 3361, 4213, 11826, 1994, 2193, 2036, 17, 3728, 3567, 17, 6635, 5116, 1958, 2119, 5542, 17615, 1036, 18, 2256, 4308, 4595, 1930, 65, 16, 2038, 20967, 8944, 1920, 2288, 8269, 17, 6125, 9761, 2193, 1920, 11826, 1994, 1958, 1920, 7691, 4184, 5961, 16, 6098, 5880, 9112, 1977, 7179, 2037, 1920, 2288, 11473, 8887, 9761, 12, 6080, 2095, 13, 18, 2038, 14103, 7496, 7468, 1966, 43, 2931, 1927, 5961, 2495, 3081, 18, 7496, 7468, 3333, 1942, 1920, 7468, 2037, 6933, 4165, 2469, 2136, 4075, 2162, 2252, 7247, 1942, 68, 17, 3888, 18, 18563, 4558, 43, 3059, 3536, 1942, 2634, 5961, 2495, 16, 2321, 2651, 1930, 3436, 3130, 18, 4647, 17, 17701, 19110, 18, 6801, 2037, 1920, 4080, 3504, 16, 43, 7187, 3072, 3504, 1982, 7000, 2007, 3476, 5041, 11473, 7555, 1958, 2362, 5880, 1919, 2106, 18, 8269, 3476, 3251, 1985, 2593, 2007, 10880, 1920, 2758, 6263, 1958, 2288, 6266, 12475, 11473, 18, 1958, 2362, 5880, 1919, 2106, 16, 1920, 2529, 1927, 11189, 3476, 3251, 1982, 5656, 3586, 1920, 3980, 8269, 6500, 18, 2038, 9575, 43, 17998, 4659, 4884, 2597, 3281, 15042, 1927, 19110, 1985, 7796, 2037, 1920, 2501, 17, 3998, 7187, 3072, 3504, 18, 43, 4096, 3504, 1982, 3999, 2037, 1920, 2561, 7187, 3072, 3504, 2007, 20116, 2637, 9, 1927, 1920, 5253, 1958, 4213, 18, 4213, 3604, 1958, 1920, 7187, 3072, 4096, 3504, 2322, 1977, 2522, 1922, 6934, 2095, 18, 2469, 17651, 2052, 3604, 1956, 1920, 7861, 2166, 3072, 17, 3504, 2322, 16, 2038, 5789, 1920, 20481, 17, 10326, 5447, 1942, 3679, 5169, 1920, 4737, 1927, 3700, 8677, 18, 2193, 1920, 11231, 7002, 1956, 43, 9579, 2991, 1927, 22421, 30, 1920, 3113, 2154, 7422, 43, 30276, 1927, 20, 18, 3287, 1942, 20, 18, 4922, 30, 2038, 9421, 1990, 1920, 3700, 21, 9, 1927, 8677, 12, 6934, 2095, 13, 18, 43, 2340, 17, 11175, 12352, 2723, 2188, 2648, 1982, 2251, 1942, 2634, 3053, 5961, 17, 2487, 4213, 11826, 26518, 2037, 1920, 7861, 2166, 3072, 3504, 13862, 2690, 2037, 1920, 2561, 7187, 3072, 3504, 12, 5159, 2545, 13, 18, 2359, 2735, 19377, 14010, 18, 2038, 2593, 43, 19377, 14010, 2333, 1958, 2461, 2359, 5704, 30, 1920, 2607, 17355, 11526, 1014, 2359, 5704, 1930, 3878, 30, 1942, 2634, 1920, 2495, 1927, 20544, 1999, 1990, 5961, 17, 2487, 3604, 12, 11461, 2095, 13, 18, 2288, 2979, 17, 7619, 19377, 14010, 14995, 1985, 3845, 30, 6267, 20116, 1930, 8269, 20116, 18, 1958, 43, 2487, 2359, 2735, 1930, 7363, 16, 2038, 17476, 43, 4466, 1927, 1920, 2359, 2735, 1930, 3561, 1920, 3980, 5961, 11, 61, 11826, 1994, 18, 2038, 3747, 43, 3109, 1927, 9655, 1930, 2593, 5656, 19377, 14010, 21125, 1958, 2362, 4466, 18, 3137, 11484, 2359, 7139, 18, 2038, 5450, 4804, 1025, 2628, 2037, 1920, 7139, 3193, 1927, 1920, 3137, 11484, 2333, 18, 2561, 2038, 5450, 2628, 1922, 1920, 6091, 8709, 3031, 12, 13346, 2037, 2160, 3223, 1942, 20298, 9932, 1990, 5597, 26, 13, 2810, 1942, 1920, 2796, 3114, 1927, 8611, 15772, 2052, 3031, 3165, 2980, 3626, 17, 8126, 2031, 3012, 17, 2565, 7096, 18, 2812, 16, 2038, 5450, 6770, 3012, 2628, 30, 2149, 17, 5203, 3065, 2628, 2037, 1920, 12385, 13649, 1930, 2568, 2628, 1958, 1920, 3751, 17839, 1028, 17, 13169, 6971, 18, 2038, 16640, 2628, 1922, 8611, 19264, 1956, 1920, 6770, 2628, 2007, 10566, 30, 21, 13, 7351, 3709, 1927, 16504, 1954, 2228, 2628, 12, 2193, 1920, 3751, 17839, 1028, 17, 3428, 4223, 1036, 58, 17, 2851, 13, 1988, 3063, 43, 6770, 2359, 31, 1930, 22, 13, 2149, 17, 5203, 4067, 2628, 2037, 1920, 12385, 13649, 18, 2753, 7901, 16, 11844, 1009, 2628, 1985, 16504, 1954, 2228, 1922, 5880, 1028, 18, 25, 16, 3006, 1927, 2154, 13862, 1920, 3504, 17, 2454, 7139, 4683, 18, 2193, 43, 11602, 1021, 5573, 2648, 1958, 28963, 2128, 2808, 18326, 16, 2038, 3561, 1920, 5485, 1927, 6266, 12475, 24, 1927, 1920, 11844, 1009, 2628, 1930, 11180, 22614, 2019, 3464, 23, 1927, 1920, 24, 1990, 3751, 17839, 1028, 12, 6080, 2545, 13, 18, 2230, 6855, 18, 3365, 4062, 17, 22365, 7527, 1958, 1920, 6184, 2230, 1930, 26472, 2230, 1958, 4580, 5327, 18, 1920, 13537, 4558, 3281, 6151, 12, 5894, 30, 19, 19, 21997, 18, 21509, 19, 2573, 17, 2628, 19, 13013, 1036, 19, 13, 1966, 2486, 1966, 1925, 6854, 1958, 7233, 6777, 1029, 2274, 12, 5894, 30, 19, 19, 21997, 18, 21509, 19, 2573, 17, 2628, 19, 7233, 4127, 19, 13, 18, 5539, 2712, 7815, 1977, 3322, 2037, 1920, 24913, 18868, 12, 11582, 30, 19, 19, 24913, 18, 2008, 19, 6781, 1980, 22629, 19, 21997, 3940, 13, 18, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = tokenizer(test_text)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] methods. ethics statement. this study was approved by the ucsf institutional review board on human subjects under protocol # 10 - 00104. heterogeneous networks. we created a general framework and open source software package for representing heterogeneous networks. like traditional graphs, heterogeneous networks consist of nodes connected by edges, except that an additional meta layer defines type. node type signifies the kind of entity encoded, whereas edge type signifies the kind of relationship encoded. edge types are comprised of a source node type, target node type, kind ( to differentiate between multiple edge types connecting the same node types ), and direction ( allowing for both directed and undirected edge types ). the user defines these types and annotates each node and edge, upon creation, with its corresponding type. the meta layer itself can be represented as a graph consisting of node types connected by edge types. when referring to this graph of types, we use the prefix\\'meta \\'. metagraphs : called schemas in previous work : consist of metanodes connected by metaedges. in a heterogeneous network, each path, a series of edges with common intermediary nodes, corresponds to a metapath representing the type of path. a path\\'s metapath is the series of metaedges corresponding to that path\\'s edges. the possible metapaths within a heterogeneous network can be enumerated by traversing the metagraph. we implemented this framework as an object - oriented data structure in python and named the resulting package hetio. users are free to browse, use, or contribute to the software, through the online repository ( https : / / github. com / dhimmel / hetio ). network construction. the included resources, and hence the metaedges and metanodes composing our network, were selected empirically based on a balance among the following properties : 1 ) quality : relevance to human pathogenesis ; high accuracy and an optimal trade - off between false positives and false negatives. in some cases, quality concerns prevented the inclusion of a desired metaedge. for example, we omitted ontology - based disease similarly due to an inaccurate disease ontology hierarchy, and we omitted disease comorbidity due to high measurement error for uncommon diseases. for included metaedges, we attempted to select the highest quality resource in that domain. 2 ) reusability : easily retrievable and parsable ; mapped to controlled vocabularies ; well documented ; amenable to reproducible ( scripted ) analysis ; free of prohibitive reuse stipulations. 3 ) throughput : broad domain - specific coverage generated using systematic platforms that minimize bias. while genetic interactions have previously proven informative, their sparse characterization in humans was deemed unfavorable for our approach. 4 ) diversified, multiscale portrayal of biology : capturing, in aggregate, many aspects of pathophysiology across multiple levels of biological complexity. levels of the hierarchical architecture of biological complexity include the genome, transcriptome, proteome, interactome, metabolome, cell and tissue organization, and phenome. balancing these considerations, we integrated as many resources as possible within our computational runtime constraints. nodes. protein - coding genes ( s3 data ) were extracted from the hgnc database. resources were mapped to hgnc terms via gene symbol ( ambiguous symbols were resolved in the order : approved, previous, synonyms ) or entrez identifiers. disease nodes ( s6 and s7 data ) were taken from the disease ontology ( do ). due to the limited number of diseases with gwas, relevant disease references were manually mapped to the do ( s11 data ). tissues were taken from the brenda tissue ontology ( bto ). only tissues with profiled expression were included enabling manual mapping. nodes for the 14 msigdb metanodes were directly imported from the molecular signature database version 4. 0. all msigdb collections were included except those that were supersets of other collections. for example,\\'c3 : motif gene sets\\'was the union of two disjoint collections (\\'c3 : microrna targets\\'and\\'c3 : transcription factor targets\\') and was therefore excluded. diseases were classified manually into 10 categories according to pathophysiology. the\\'idiopathic\\'and\\'unspecific\\'categories were not included as pathophysiology nodes, since they do not signify meaningful similarities between member diseases. associations. disease - gene associations were extracted from the gwas catalog, a compilation of gwas associations where p < 10 - 5. first, associations were segregated by disease. gwas catalog phenotypes were converted to experimental factor ontology ( efo ) terms using mappings produced by the european bioinformatics institute. associations mapping to multiple efo terms were excluded to eliminate cross - phenotype studies. we manually mapped efo to do terms ( now included in the do as cross - references ) and annotated each do term with its associations. associations were classified as either high or low - confidence, where exceeding two thresholds granted high - confidence status. first, p < = 5 * 10 - 8 corresponding to p < = 0. 05 after bonferroni adjustment for one million comparisons ( an approximate upper bound for the number of independent snps evaluated by most gwas ). second, a minimum sample size ( counting both cases and controls ) of 1, 000 was required, since studies below this size are underpowered : i. e. any discovered associations are more likely than not to be false : for the majority of true effect size distributions commonly assumed to underlie complex disease etiology. lead - snps were assigned windows : regions wherein the causal snps are assumed to lie : retrieved from the dapple server. windows were calculated for each lead - snp by finding the furthest upstream and downstream snps where r 2 > 0. 5 and extending outwards to the next recombination hotspot. associations were ordered by confidence, sorting on following criteria : high / low confidence, p - value ( low to high ), and recency. in order of confidence, associations were overlapped by their windows into disease - specific loci ( s4 data ). by organizing associations into loci, associations from multiple studies tagging the same underlying signal were condensed ( s1 fig ). a locus was classified as high - confidence if any of its composite associations were high - confidence and low - confidence otherwise. for each disease - specific loci, we attempted to identify a primary gene. the primary gene was resolved in the following order : 1 ) the mode author - reported gene ; 2 ) the containing gene for an intragenic lead - snp ; 3 ) the mode author - reported gene for an intragenic lead - snp ( in the case of overlapping genes ) ; 4 ) the mode author - reported gene of the most proximal up and downstream genes. steps 2 - 4 were repeated on each association composing the loci, in order of confidence, until a single gene resolved as primary. loci where ambiguity was unresolvable or where no genes were returned did not receive a primary gene. all non - primary genes : genes that were author - reported, overlapping the lead - snp, or immediately up or downstream from the lead - snp : were considered secondary. accordingly, four categories of processed associations were created : high - confidence primary, high - confidence secondary, low - confidence primary, and low - confidence secondary ( s5 data ). we assume that our primary gene annotation for each loci represents the single causal gene responsible for the association. to investigate the validity of this assumption, we evaluated the performance of our predictions separately using each category of association as positives ( s8 fig ). for both confidence levels, primary associations outperformed secondary associations suggesting our method succeeded at categorizing causal genes as primary. however, for high - confidence secondary associations, the auroc equaled 0. 74, which could result from multiple causal genes per loci or categorizing sole causal genes as secondary. the performance decline from high to low confidence associations was severe, pointing to a preponderance of falsely identified loci in the gwas catalog when p > 5x10 - 8 or sample size drops below 1000. protein interactions. physical protein - protein interactions ( s8 data ) were extracted from irefindex 12. 0, a compilation of 15 primary interaction databases. the irefindex was processed with ppitrim to convert proteins to genes, remove protein complexes, and condense duplicated entries. tissue - specific gene expression. tissue - specific gene expression levels ( s9 data ) were extracted from the gnf gene expression atlas. starting with the gcrma - normalized and multisample - averaged expression values, 44, 775 probes were converted to 16, 466 hgnc genes and 84 tissues were manually mapped and converted to 77 bto terms. for both conversions, the geometric mean was used to average expression values. the log base 10 of expression value was used as the threshold criteria for get edge inclusion. disease localization. disease localization was calculated for the 77 tissues with expression profiles ( s10 data ). literature co - occurrence was used to assess whether a tissue is affected by a disease. we used copub 5. 0 to extract r - scaled scores between tissues and diseases measuring whether two terms occurred together in medline abstracts more than would be expected by chance. do terms for diseases with gwas and bto tissues with expression profiles were manually mapped to the\\'biological identifier\\'terminology used by copub. the r - scaled score was used as the threshold criteria for tld edge inclusion. feature computation metrics. the simplest metapath - based metric is path count ( pc ) : the number of paths, of a specified metapath, between a source and target node. however, pc does not adjust for the extent of graph connectivity along the path. paths traversing high - degree nodes will account for a large portion of the pc, despite high - degree nodes frequently representing a biologically broad or vague entity with little informativeness. the previous work evaluated several metrics that include a pc denominator to adjust for connectivity and reported that normalized path count ( npc ) performed best. the denominator for npc equals the number of paths from the source to any target plus the number of paths from any target to the source. where m is the metapath, s is the source node, t is the target node, s m is the set of nodes corresponding to the source metanode of m, and t m is the set of nodes corresponding to the target metanode of m. we adopt the any source / target concept to compute the two gad features. however, dividing the pc by a denominator is flawed because each path composing the pc deserves a distinct degree adjustment. if two paths : one traversing only high - degree nodes and one traversing only low - degree nodes : compose the pc, the network surrounding the high - degree path will monopolize the npc denominator and overwhelm the contribution of the low - degree path despite its specificity. therefore, we developed the degree - weighted path count ( dwpc ) which individually downweights each path between a source and target node. each path receives a path - degree product ( pdp ) calculated by : 1 ) extracting all metaedge - specific degrees along the path ( d path ), where each edge composing the path contributes two degrees ; 2 ) raising each degree to the - w power, where w > = 0 and is called the damping exponent ; 3 ) multiplying all exponentiated degrees to yield the pdp. the dwpc equals the sum of pdps. see fig 2c and 2d for a visual description of the dwpc. machine learning approach. pathpredict relied on basic logistic regression to predict coauthorship status from features corresponding to nine distinct metapaths. however, faced with fewer positives to train our model and a large number of features, we adopted a regularized approach, which aims to contain the overfitting tendencies inherent to regression. regularization penalizes complexity, a trademark of overfitting. we chose the elastic net technique of regularization, which is efficiently implemented for logistic regression by the r glmnet package. regularized logistic regression requires a parameter, lambda, setting the strength of regularization. we optimized lambda separately for each model fit. using 10 - fold cross - validation and the \" one - standard - error \" rule to choose the optimal lambda from deviance, we adopted a conservative approach designed to prevent overfitting. on the training set of gene - disease pairs, we optimized the elastic net mixing parameter ( alpha ), the dwpc damping exponent ( w ), and two edge inclusion thresholds. first, we optimized alpha and w on the 20 features whose metapaths did not include threshold - dependent metaedges. for each combination of alpha and w, we calculated average testing auroc using 20 - fold cross - validation repeated for 10 randomized partitionings. after setting alpha and w, we jointly optimized the two edge - inclusion thresholds using the auroc for the getld feature, whose metapath is composed from the two edges requiring thresholds ( s3 fig ). we adopt standardized coefficients as a measure of feature effect size. standardized coefficients refer to the coefficients from logistic regression when all features have been transformed to z - scores. standardization provides a common scale to assess feature effect, both within and across models. degree - preserving permutation. starting from the complete network, a permuted network was created by swapping edges separately for each metaedge. edge swaps were performed by switching the target nodes for two randomly selecting edges. for each metaedge, the number of attempted swaps was ten times the corresponding edge count. we adopted a markov chain strategy where additional rounds of permutation were initiated from the most - recently permuted network. a training network was generated from the first permuted network by masking 25 % of the associations for testing. testing performance for the permuted training network model is shown in s4 fig. when contrasting this performance with the unpermuted - network model, we employed the condensed - roc curve to magnify the importance of top predictions. using the exponential transformation with a magnification factor of 460 : the value which maps a fpr of 0. 01 to 0. 99 : we concentrated on the top 1 % of predictions ( s4 fig ). a one - sided unpaired delong test was used to assess whether feature - specific testing aurocs from the unpermuted network exceeded those from the first permuted network ( s2 table ). gene set subsampling. we performed a subsampling analysis for 15 gene sets : the 14 msigdb gene sets and tissues : to assess the effect of sparsity on feature - specific performance ( s7 fig ). two without - replacement subsampling schemes were investigated : node masking and edge masking. for a specific gene set and scheme, we masked a percentage of the gene set and calculated the corresponding feature\\'s auroc. we evaluated a range of percentages and performed ten subsampling repetitions for each percentage. multiple sclerosis gene discovery. we excluded 588 genes from the discovery phase of the multiple sclerosis analysis. first we excluded genes in the extended mhc region ( spanning from scgn to syngap1 on chromosome 6 ) due to the complex pattern of linkage characterizing this region containing several highly - penetrant ms - risk alleles. second, we excluded putative ms genes : high - confidence primary genes from the gwas catalog and reported genes for the wtccc2 - replicated loci. we omitted genes in linkage disequilibrium with the putative genes by excluding : 1 ) consecutive sequences of nominally significant genes ( using the wtccc2 - vegas p - values ) that included a putative gene ; and 2 ) high - confidence secondary genes from the gwas catalog. post exclusion, 1211 genes were nominally significant in meta2. 5, four of which exceeded the network - based discovery threshold. using a hypergeometric test for overrepresentation, we calculated the probability of randomly selecting 4 of the 1211 genes and bonferroni validating at least 3 of the 4 on wtccc2 ( s3 table ). data availability. see s1 - s12 datasets for the supporting data and s13 data for vector figures. the website provides additional resources ( http : / / het. io / disease - genes / downloads / ) as well as an interface for browsing results ( http : / / het. io / disease - genes / browse / ). project related code is available from the github repository ( https : / / github. com / dhimmel / hetio ). [SEP]'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(e[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pubmed-rag-iB5Z1S4t-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
